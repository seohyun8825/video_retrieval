                                                                                                    
{'loss': 4.8249, 'grad_norm': 121.13385449631014, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 3.916, 'grad_norm': 105.83926196699154, 'learning_rate': 1.4492753623188408e-07, 'epoch': 0.0}
{'loss': 3.6476, 'grad_norm': 66.7571935954094, 'learning_rate': 2.8985507246376816e-07, 'epoch': 0.0}
{'loss': 4.343, 'grad_norm': 133.17164662045766, 'learning_rate': 4.347826086956522e-07, 'epoch': 0.01}
{'loss': 4.4382, 'grad_norm': 125.1568067935807, 'learning_rate': 5.797101449275363e-07, 'epoch': 0.01}
{'loss': 5.0348, 'grad_norm': 133.19396326130288, 'learning_rate': 7.246376811594204e-07, 'epoch': 0.01}
{'loss': 4.2959, 'grad_norm': 118.34805553840236, 'learning_rate': 8.695652173913044e-07, 'epoch': 0.01}
{'loss': 4.5923, 'grad_norm': 88.87216270977443, 'learning_rate': 1.0144927536231885e-06, 'epoch': 0.01}
{'loss': 4.1474, 'grad_norm': 92.74049127065048, 'learning_rate': 1.1594202898550726e-06, 'epoch': 0.01}
{'loss': 4.7178, 'grad_norm': 88.57346975013232, 'learning_rate': 1.3043478260869566e-06, 'epoch': 0.01}
{'loss': 3.8007, 'grad_norm': 107.490859412267, 'learning_rate': 1.4492753623188408e-06, 'epoch': 0.02}
{'loss': 3.952, 'grad_norm': 97.66028009114464, 'learning_rate': 1.5942028985507246e-06, 'epoch': 0.02}
{'loss': 3.4804, 'grad_norm': 114.57959628789348, 'learning_rate': 1.7391304347826088e-06, 'epoch': 0.02}
{'loss': 3.6714, 'grad_norm': 63.2310012648724, 'learning_rate': 1.884057971014493e-06, 'epoch': 0.02}
{'loss': 3.2433, 'grad_norm': 60.06715272162168, 'learning_rate': 2.028985507246377e-06, 'epoch': 0.02}
{'loss': 3.0161, 'grad_norm': 75.02054160680544, 'learning_rate': 2.173913043478261e-06, 'epoch': 0.02}
{'loss': 2.4489, 'grad_norm': 62.56517694026555, 'learning_rate': 2.3188405797101453e-06, 'epoch': 0.02}
{'loss': 3.2927, 'grad_norm': 46.323331416177965, 'learning_rate': 2.4637681159420295e-06, 'epoch': 0.03}
{'loss': 2.9082, 'grad_norm': 55.23717034464238, 'learning_rate': 2.6086956521739132e-06, 'epoch': 0.03}
{'loss': 2.9076, 'grad_norm': 58.833628806927535, 'learning_rate': 2.7536231884057974e-06, 'epoch': 0.03}
{'loss': 2.5467, 'grad_norm': 49.0305696100565, 'learning_rate': 2.8985507246376816e-06, 'epoch': 0.03}
{'loss': 2.792, 'grad_norm': 48.878732375331374, 'learning_rate': 3.043478260869566e-06, 'epoch': 0.03}
{'loss': 1.7407, 'grad_norm': 38.31924149871102, 'learning_rate': 3.188405797101449e-06, 'epoch': 0.03}
{'loss': 1.8842, 'grad_norm': 39.444101063702796, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.04}
{'loss': 2.1825, 'grad_norm': 30.26538549124546, 'learning_rate': 3.4782608695652175e-06, 'epoch': 0.04}
{'loss': 2.0795, 'grad_norm': 30.496330412984832, 'learning_rate': 3.6231884057971017e-06, 'epoch': 0.04}
{'loss': 1.9461, 'grad_norm': 37.555202577732175, 'learning_rate': 3.768115942028986e-06, 'epoch': 0.04}
{'loss': 1.9436, 'grad_norm': 35.47144021530089, 'learning_rate': 3.91304347826087e-06, 'epoch': 0.04}
{'loss': 2.6729, 'grad_norm': 36.66124402091339, 'learning_rate': 4.057971014492754e-06, 'epoch': 0.04}
{'loss': 1.5468, 'grad_norm': 33.13794210732809, 'learning_rate': 4.202898550724638e-06, 'epoch': 0.04}
{'loss': 1.7599, 'grad_norm': 34.285211332200525, 'learning_rate': 4.347826086956522e-06, 'epoch': 0.05}
{'loss': 2.1639, 'grad_norm': 45.979128489777715, 'learning_rate': 4.492753623188406e-06, 'epoch': 0.05}
{'loss': 1.3459, 'grad_norm': 31.414895316759292, 'learning_rate': 4.637681159420291e-06, 'epoch': 0.05}
{'loss': 2.1453, 'grad_norm': 29.934557084248404, 'learning_rate': 4.782608695652174e-06, 'epoch': 0.05}
{'loss': 2.3215, 'grad_norm': 35.46343146417548, 'learning_rate': 4.927536231884059e-06, 'epoch': 0.05}
{'loss': 1.9312, 'grad_norm': 35.62503450865605, 'learning_rate': 5.072463768115943e-06, 'epoch': 0.05}
{'loss': 2.0518, 'grad_norm': 49.42147121199976, 'learning_rate': 5.2173913043478265e-06, 'epoch': 0.05}
{'loss': 1.3815, 'grad_norm': 26.20014575857502, 'learning_rate': 5.362318840579711e-06, 'epoch': 0.06}
{'loss': 1.7741, 'grad_norm': 32.162110402136015, 'learning_rate': 5.507246376811595e-06, 'epoch': 0.06}
{'loss': 2.254, 'grad_norm': 33.33008121537806, 'learning_rate': 5.652173913043479e-06, 'epoch': 0.06}
{'loss': 1.4467, 'grad_norm': 30.480664990342337, 'learning_rate': 5.797101449275363e-06, 'epoch': 0.06}
{'loss': 2.1807, 'grad_norm': 27.815768526232308, 'learning_rate': 5.942028985507247e-06, 'epoch': 0.06}
{'loss': 1.2479, 'grad_norm': 30.546824843951185, 'learning_rate': 6.086956521739132e-06, 'epoch': 0.06}
{'loss': 1.5365, 'grad_norm': 23.13474304099505, 'learning_rate': 6.2318840579710145e-06, 'epoch': 0.06}
{'loss': 2.1312, 'grad_norm': 30.076499139869593, 'learning_rate': 6.376811594202898e-06, 'epoch': 0.07}
{'loss': 1.5034, 'grad_norm': 27.21258869871593, 'learning_rate': 6.521739130434783e-06, 'epoch': 0.07}
{'loss': 1.6886, 'grad_norm': 29.37242822684988, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.07}
{'loss': 1.6127, 'grad_norm': 25.21682587286755, 'learning_rate': 6.811594202898551e-06, 'epoch': 0.07}
{'loss': 1.8093, 'grad_norm': 26.139456764488173, 'learning_rate': 6.956521739130435e-06, 'epoch': 0.07}
{'loss': 1.971, 'grad_norm': 24.389460767645982, 'learning_rate': 7.10144927536232e-06, 'epoch': 0.07}
{'loss': 1.4043, 'grad_norm': 34.407428722101066, 'learning_rate': 7.246376811594203e-06, 'epoch': 0.07}
{'loss': 1.4845, 'grad_norm': 37.26511990391937, 'learning_rate': 7.391304347826087e-06, 'epoch': 0.08}
{'loss': 1.2775, 'grad_norm': 26.588846570800445, 'learning_rate': 7.536231884057972e-06, 'epoch': 0.08}
{'loss': 1.5779, 'grad_norm': 39.02504648435889, 'learning_rate': 7.681159420289856e-06, 'epoch': 0.08}
{'loss': 2.022, 'grad_norm': 28.466514615163927, 'learning_rate': 7.82608695652174e-06, 'epoch': 0.08}
{'loss': 1.592, 'grad_norm': 32.92892398956402, 'learning_rate': 7.971014492753623e-06, 'epoch': 0.08}
{'loss': 1.5872, 'grad_norm': 29.340645415132254, 'learning_rate': 8.115942028985508e-06, 'epoch': 0.08}
{'loss': 0.9299, 'grad_norm': 23.336156157992455, 'learning_rate': 8.260869565217392e-06, 'epoch': 0.08}
{'loss': 1.6333, 'grad_norm': 27.751993455335967, 'learning_rate': 8.405797101449275e-06, 'epoch': 0.09}
{'loss': 1.1481, 'grad_norm': 27.98828593887133, 'learning_rate': 8.55072463768116e-06, 'epoch': 0.09}
{'loss': 0.9226, 'grad_norm': 23.496669652760296, 'learning_rate': 8.695652173913044e-06, 'epoch': 0.09}
{'loss': 1.2636, 'grad_norm': 23.74150274924357, 'learning_rate': 8.840579710144929e-06, 'epoch': 0.09}
{'loss': 1.1156, 'grad_norm': 22.100114281982368, 'learning_rate': 8.985507246376812e-06, 'epoch': 0.09}
{'loss': 1.1379, 'grad_norm': 22.859475565239602, 'learning_rate': 9.130434782608697e-06, 'epoch': 0.09}
{'loss': 1.6468, 'grad_norm': 27.315660200601023, 'learning_rate': 9.275362318840581e-06, 'epoch': 0.09}
{'loss': 1.6168, 'grad_norm': 26.013058385421758, 'learning_rate': 9.420289855072464e-06, 'epoch': 0.1}
{'loss': 1.3142, 'grad_norm': 23.478053639159914, 'learning_rate': 9.565217391304349e-06, 'epoch': 0.1}
{'loss': 1.3738, 'grad_norm': 26.40935882553883, 'learning_rate': 9.710144927536233e-06, 'epoch': 0.1}
{'loss': 0.9719, 'grad_norm': 21.997040457601944, 'learning_rate': 9.855072463768118e-06, 'epoch': 0.1}
{'loss': 1.0219, 'grad_norm': 27.24447327477912, 'learning_rate': 1e-05, 'epoch': 0.1}
{'loss': 0.9442, 'grad_norm': 22.845794377243905, 'learning_rate': 9.999934975445053e-06, 'epoch': 0.1}
{'loss': 1.3911, 'grad_norm': 24.960083878515466, 'learning_rate': 9.999739903471488e-06, 'epoch': 0.11}
{'loss': 0.8069, 'grad_norm': 17.05792423881619, 'learning_rate': 9.999414789153093e-06, 'epoch': 0.11}
{'loss': 1.2429, 'grad_norm': 18.815432525700825, 'learning_rate': 9.998959640946033e-06, 'epoch': 0.11}
{'loss': 0.4613, 'grad_norm': 18.572418912738765, 'learning_rate': 9.998374470688632e-06, 'epoch': 0.11}
{'loss': 1.6787, 'grad_norm': 26.83997606565174, 'learning_rate': 9.997659293601066e-06, 'epoch': 0.11}
{'loss': 2.7336, 'grad_norm': 37.35955617068371, 'learning_rate': 9.99681412828496e-06, 'epoch': 0.11}
{'loss': 1.8297, 'grad_norm': 36.456746146539395, 'learning_rate': 9.995838996722916e-06, 'epoch': 0.11}
{'loss': 0.9537, 'grad_norm': 30.74251233823713, 'learning_rate': 9.99473392427793e-06, 'epoch': 0.12}
{'loss': 1.1291, 'grad_norm': 19.162982419845875, 'learning_rate': 9.993498939692744e-06, 'epoch': 0.12}
{'loss': 1.2564, 'grad_norm': 25.384599062825895, 'learning_rate': 9.992134075089085e-06, 'epoch': 0.12}
{'loss': 1.6999, 'grad_norm': 27.792218452668134, 'learning_rate': 9.990639365966835e-06, 'epoch': 0.12}
{'loss': 2.0045, 'grad_norm': 34.03291897649859, 'learning_rate': 9.989014851203118e-06, 'epoch': 0.12}
{'loss': 1.2724, 'grad_norm': 25.096624025194632, 'learning_rate': 9.987260573051268e-06, 'epoch': 0.12}
{'loss': 0.836, 'grad_norm': 25.012970374370536, 'learning_rate': 9.985376577139753e-06, 'epoch': 0.12}
{'loss': 1.8706, 'grad_norm': 27.971934163644587, 'learning_rate': 9.983362912470967e-06, 'epoch': 0.13}
{'loss': 0.9198, 'grad_norm': 20.36345963077775, 'learning_rate': 9.98121963141997e-06, 'epoch': 0.13}
{'loss': 1.274, 'grad_norm': 24.10856731029733, 'learning_rate': 9.978946789733126e-06, 'epoch': 0.13}
{'loss': 1.2298, 'grad_norm': 22.867310158729122, 'learning_rate': 9.976544446526634e-06, 'epoch': 0.13}
{'loss': 1.4286, 'grad_norm': 22.131482760667435, 'learning_rate': 9.97401266428502e-06, 'epoch': 0.13}
{'loss': 1.5701, 'grad_norm': 22.814696827588197, 'learning_rate': 9.971351508859488e-06, 'epoch': 0.13}
{'loss': 1.942, 'grad_norm': 24.19327695898818, 'learning_rate': 9.968561049466214e-06, 'epoch': 0.13}
{'loss': 0.7948, 'grad_norm': 20.643001255240033, 'learning_rate': 9.965641358684552e-06, 'epoch': 0.14}
{'loss': 0.618, 'grad_norm': 21.2639617155393, 'learning_rate': 9.96259251245514e-06, 'epoch': 0.14}
{'loss': 0.6896, 'grad_norm': 18.96532917134833, 'learning_rate': 9.959414590077925e-06, 'epoch': 0.14}
{'loss': 1.5957, 'grad_norm': 26.670545988696873, 'learning_rate': 9.9561076742101e-06, 'epoch': 0.14}
{'loss': 0.5603, 'grad_norm': 16.007845012111826, 'learning_rate': 9.952671850863963e-06, 'epoch': 0.14}
{'loss': 1.7337, 'grad_norm': 30.176731975292455, 'learning_rate': 9.949107209404664e-06, 'epoch': 0.14}
{'loss': 1.0001, 'grad_norm': 28.793386542635552, 'learning_rate': 9.945413842547894e-06, 'epoch': 0.14}
{'loss': 1.0897, 'grad_norm': 18.20445252227653, 'learning_rate': 9.941591846357467e-06, 'epoch': 0.15}
{'loss': 0.6589, 'grad_norm': 23.447299655957316, 'learning_rate': 9.937641320242823e-06, 'epoch': 0.15}
{'loss': 0.9985, 'grad_norm': 19.09986050342525, 'learning_rate': 9.933562366956445e-06, 'epoch': 0.15}
{'loss': 0.681, 'grad_norm': 22.55278301508696, 'learning_rate': 9.92935509259118e-06, 'epoch': 0.15}
{'loss': 1.0288, 'grad_norm': 21.287198977631483, 'learning_rate': 9.925019606577486e-06, 'epoch': 0.15}
{'loss': 1.5626, 'grad_norm': 24.08017840619862, 'learning_rate': 9.92055602168058e-06, 'epoch': 0.15}
{'loss': 0.3436, 'grad_norm': 12.42808200329366, 'learning_rate': 9.915964453997516e-06, 'epoch': 0.15}
{'loss': 1.0267, 'grad_norm': 15.686346750733062, 'learning_rate': 9.911245022954146e-06, 'epoch': 0.16}
{'loss': 1.5872, 'grad_norm': 27.40555175077103, 'learning_rate': 9.906397851302036e-06, 'epoch': 0.16}
{'loss': 1.207, 'grad_norm': 17.682879033259198, 'learning_rate': 9.901423065115254e-06, 'epoch': 0.16}
{'loss': 1.2141, 'grad_norm': 18.289268231511684, 'learning_rate': 9.896320793787106e-06, 'epoch': 0.16}
{'loss': 1.2693, 'grad_norm': 23.498282946937717, 'learning_rate': 9.89109117002676e-06, 'epoch': 0.16}
{'loss': 1.5743, 'grad_norm': 28.65132319116289, 'learning_rate': 9.885734329855798e-06, 'epoch': 0.16}
{'loss': 0.8619, 'grad_norm': 20.411543603042574, 'learning_rate': 9.880250412604681e-06, 'epoch': 0.16}
{'loss': 1.6245, 'grad_norm': 22.31597644237166, 'learning_rate': 9.874639560909118e-06, 'epoch': 0.17}
{'loss': 0.9433, 'grad_norm': 20.87262409144504, 'learning_rate': 9.868901920706366e-06, 'epoch': 0.17}
{'loss': 1.1368, 'grad_norm': 20.682628385988345, 'learning_rate': 9.863037641231424e-06, 'epoch': 0.17}
{'loss': 1.4186, 'grad_norm': 26.452708171872434, 'learning_rate': 9.857046875013154e-06, 'epoch': 0.17}
{'loss': 0.7261, 'grad_norm': 17.52146742670136, 'learning_rate': 9.850929777870324e-06, 'epoch': 0.17}
{'loss': 0.471, 'grad_norm': 18.704158334994606, 'learning_rate': 9.844686508907538e-06, 'epoch': 0.17}
{'loss': 0.6068, 'grad_norm': 20.562337718836716, 'learning_rate': 9.838317230511111e-06, 'epoch': 0.18}
{'loss': 0.4778, 'grad_norm': 14.26337437544795, 'learning_rate': 9.831822108344841e-06, 'epoch': 0.18}
{'loss': 1.322, 'grad_norm': 27.811941663418565, 'learning_rate': 9.8252013113457e-06, 'epoch': 0.18}
{'loss': 1.392, 'grad_norm': 23.54563851785662, 'learning_rate': 9.818455011719439e-06, 'epoch': 0.18}
{'loss': 0.9011, 'grad_norm': 20.72773926504818, 'learning_rate': 9.811583384936108e-06, 'epoch': 0.18}
{'loss': 1.6114, 'grad_norm': 30.959758748966532, 'learning_rate': 9.804586609725499e-06, 'epoch': 0.18}
{'loss': 0.5715, 'grad_norm': 17.69450924570419, 'learning_rate': 9.797464868072489e-06, 'epoch': 0.18}
{'loss': 1.0507, 'grad_norm': 22.344878974688115, 'learning_rate': 9.790218345212309e-06, 'epoch': 0.19}
{'loss': 2.0835, 'grad_norm': 27.834401753037504, 'learning_rate': 9.782847229625729e-06, 'epoch': 0.19}
{'loss': 1.2779, 'grad_norm': 19.0884362393319, 'learning_rate': 9.775351713034155e-06, 'epoch': 0.19}
{'loss': 0.7566, 'grad_norm': 20.07453282182835, 'learning_rate': 9.767731990394638e-06, 'epoch': 0.19}
{'loss': 0.4276, 'grad_norm': 16.07591022130798, 'learning_rate': 9.759988259894808e-06, 'epoch': 0.19}
{'loss': 0.8414, 'grad_norm': 18.999412654421615, 'learning_rate': 9.752120722947717e-06, 'epoch': 0.19}
{'loss': 1.1713, 'grad_norm': 25.046922513576806, 'learning_rate': 9.744129584186599e-06, 'epoch': 0.19}
{'loss': 0.474, 'grad_norm': 12.946625052344537, 'learning_rate': 9.736015051459551e-06, 'epoch': 0.2}
{'loss': 1.3392, 'grad_norm': 22.373406036129765, 'learning_rate': 9.727777335824124e-06, 'epoch': 0.2}
{'loss': 2.5573, 'grad_norm': 31.938201329672793, 'learning_rate': 9.719416651541839e-06, 'epoch': 0.2}
{'loss': 0.7191, 'grad_norm': 26.744050857747222, 'learning_rate': 9.710933216072602e-06, 'epoch': 0.2}
{'loss': 0.703, 'grad_norm': 17.32548529862758, 'learning_rate': 9.702327250069058e-06, 'epoch': 0.2}
{'loss': 0.4543, 'grad_norm': 16.7787478142246, 'learning_rate': 9.693598977370855e-06, 'epoch': 0.2}
{'loss': 2.1048, 'grad_norm': 27.930179959829548, 'learning_rate': 9.68474862499881e-06, 'epoch': 0.2}
{'loss': 1.0733, 'grad_norm': 28.823760608772396, 'learning_rate': 9.675776423149013e-06, 'epoch': 0.21}
{'loss': 1.0885, 'grad_norm': 42.42806211901582, 'learning_rate': 9.666682605186834e-06, 'epoch': 0.21}
{'loss': 1.489, 'grad_norm': 26.3768520628466, 'learning_rate': 9.657467407640864e-06, 'epoch': 0.21}
{'loss': 1.1373, 'grad_norm': 59.95860848638475, 'learning_rate': 9.648131070196749e-06, 'epoch': 0.21}
{'loss': 1.3691, 'grad_norm': 19.012245849650206, 'learning_rate': 9.638673835690962e-06, 'epoch': 0.21}
{'loss': 1.5031, 'grad_norm': 23.039287308769243, 'learning_rate': 9.62909595010449e-06, 'epoch': 0.21}
{'loss': 1.7416, 'grad_norm': 19.50197834664193, 'learning_rate': 9.619397662556434e-06, 'epoch': 0.21}
{'loss': 1.2161, 'grad_norm': 23.28623348419639, 'learning_rate': 9.609579225297524e-06, 'epoch': 0.22}
{'loss': 1.4244, 'grad_norm': 20.054331762261025, 'learning_rate': 9.599640893703568e-06, 'epoch': 0.22}
{'loss': 2.1811, 'grad_norm': 23.11148961989817, 'learning_rate': 9.589582926268798e-06, 'epoch': 0.22}
{'loss': 0.9553, 'grad_norm': 21.710343886096005, 'learning_rate': 9.579405584599157e-06, 'epoch': 0.22}
{'loss': 0.6879, 'grad_norm': 20.959566476231757, 'learning_rate': 9.569109133405495e-06, 'epoch': 0.22}
{'loss': 1.3321, 'grad_norm': 21.630377662469023, 'learning_rate': 9.558693840496666e-06, 'epoch': 0.22}
{'loss': 1.0776, 'grad_norm': 20.614401008547688, 'learning_rate': 9.548159976772593e-06, 'epoch': 0.22}
{'loss': 1.7432, 'grad_norm': 23.35077880039854, 'learning_rate': 9.537507816217191e-06, 'epoch': 0.23}
{'loss': 1.9328, 'grad_norm': 26.796168834438536, 'learning_rate': 9.526737635891262e-06, 'epoch': 0.23}
{'loss': 1.647, 'grad_norm': 24.51842237488564, 'learning_rate': 9.515849715925276e-06, 'epoch': 0.23}
{'loss': 1.4877, 'grad_norm': 24.045486467057984, 'learning_rate': 9.504844339512096e-06, 'epoch': 0.23}
{'loss': 1.2375, 'grad_norm': 22.632740777271305, 'learning_rate': 9.493721792899605e-06, 'epoch': 0.23}
{'loss': 0.9281, 'grad_norm': 20.297886213600886, 'learning_rate': 9.482482365383254e-06, 'epoch': 0.23}
{'loss': 1.6647, 'grad_norm': 27.572233866798037, 'learning_rate': 9.471126349298557e-06, 'epoch': 0.24}
{'loss': 0.5282, 'grad_norm': 21.402528996155773, 'learning_rate': 9.45965404001347e-06, 'epoch': 0.24}
{'loss': 1.0404, 'grad_norm': 19.09386658137909, 'learning_rate': 9.448065735920715e-06, 'epoch': 0.24}
{'loss': 1.2573, 'grad_norm': 25.172301893311598, 'learning_rate': 9.436361738430016e-06, 'epoch': 0.24}
{'loss': 1.6821, 'grad_norm': 26.64755486988545, 'learning_rate': 9.424542351960268e-06, 'epoch': 0.24}
{'loss': 0.8654, 'grad_norm': 20.650881235337177, 'learning_rate': 9.412607883931608e-06, 'epoch': 0.24}
{'loss': 0.9405, 'grad_norm': 20.65044650118587, 'learning_rate': 9.400558644757423e-06, 'epoch': 0.24}
{'loss': 0.6019, 'grad_norm': 16.284933522444113, 'learning_rate': 9.388394947836278e-06, 'epoch': 0.25}
{'loss': 1.7479, 'grad_norm': 27.046246986937845, 'learning_rate': 9.376117109543769e-06, 'epoch': 0.25}
{'loss': 1.5499, 'grad_norm': 22.3859728437272, 'learning_rate': 9.363725449224281e-06, 'epoch': 0.25}
{'loss': 1.1183, 'grad_norm': 24.086824025392463, 'learning_rate': 9.351220289182694e-06, 'epoch': 0.25}
{'loss': 1.1292, 'grad_norm': 19.699018018657725, 'learning_rate': 9.338601954675995e-06, 'epoch': 0.25}
{'loss': 0.6888, 'grad_norm': 16.663770448605117, 'learning_rate': 9.325870773904816e-06, 'epoch': 0.25}
{'loss': 1.6438, 'grad_norm': 25.550053667346283, 'learning_rate': 9.313027078004903e-06, 'epoch': 0.25}
{'loss': 1.8978, 'grad_norm': 26.125045478224685, 'learning_rate': 9.300071201038503e-06, 'epoch': 0.26}
[INFO|configuration_utils.py:491] 2025-12-18 18:52:38,876 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/config.json
[INFO|configuration_utils.py:757] 2025-12-18 18:52:38,877 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/generation_config.json
[INFO|modeling_utils.py:4181] 2025-12-18 18:52:41,694 >> Model weights saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/model.safetensors
[INFO|tokenization_utils_base.py:2421] 2025-12-18 18:52:41,696 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-18 18:52:41,697 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-18 18:52:41,698 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/special_tokens_map.json
/home/seohyun/.conda/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
[2025-12-18 18:52:41,974] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step175 is about to be saved!
[2025-12-18 18:52:42,053] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-18 18:52:42,054] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-18 18:52:42,342] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-18 18:52:42,413] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-18 18:52:52,420] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-18 18:52:52,421] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/global_step175/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-18 18:52:52,478] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step175 is ready now!
[INFO|image_processing_base.py:253] 2025-12-18 18:52:52,486 >> Image processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-12-18 18:52:52,490 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-18 18:52:52,495 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-18 18:52:52,498 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-12-18 18:52:52,705 >> Video processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-12-18 18:52:52,709 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-175/chat_template.jinja
                                                                                                    
{'loss': 0.9861, 'grad_norm': 16.616600477049996, 'learning_rate': 9.287003479985667e-06, 'epoch': 0.26}
{'loss': 1.3292, 'grad_norm': 18.61313303413522, 'learning_rate': 9.273824254735492e-06, 'epoch': 0.26}
{'loss': 1.0049, 'grad_norm': 25.168288567608503, 'learning_rate': 9.260533868077283e-06, 'epoch': 0.26}
{'loss': 0.6376, 'grad_norm': 16.88037790219452, 'learning_rate': 9.24713266569163e-06, 'epoch': 0.26}
{'loss': 1.5271, 'grad_norm': 25.51780813779801, 'learning_rate': 9.233620996141421e-06, 'epoch': 0.26}
{'loss': 1.5593, 'grad_norm': 24.388218760404396, 'learning_rate': 9.219999210862778e-06, 'epoch': 0.26}
{'loss': 0.6284, 'grad_norm': 22.268852201110285, 'learning_rate': 9.206267664155906e-06, 'epoch': 0.27}
{'loss': 0.4844, 'grad_norm': 14.24634911104931, 'learning_rate': 9.192426713175897e-06, 'epoch': 0.27}
{'loss': 1.3564, 'grad_norm': 19.670878704831374, 'learning_rate': 9.178476717923415e-06, 'epoch': 0.27}
{'loss': 0.8523, 'grad_norm': 19.189529442314416, 'learning_rate': 9.164418041235359e-06, 'epoch': 0.27}
{'loss': 1.7055, 'grad_norm': 23.15197673314642, 'learning_rate': 9.150251048775403e-06, 'epoch': 0.27}
{'loss': 1.3974, 'grad_norm': 20.780663066059937, 'learning_rate': 9.135976109024502e-06, 'epoch': 0.27}
{'loss': 0.6848, 'grad_norm': 18.415042837611153, 'learning_rate': 9.121593593271297e-06, 'epoch': 0.27}
{'loss': 1.3175, 'grad_norm': 21.021555450673908, 'learning_rate': 9.107103875602458e-06, 'epoch': 0.28}
{'loss': 2.2902, 'grad_norm': 28.25639624639254, 'learning_rate': 9.092507332892968e-06, 'epoch': 0.28}
{'loss': 0.3374, 'grad_norm': 11.5353799467327, 'learning_rate': 9.077804344796302e-06, 'epoch': 0.28}
{'loss': 1.812, 'grad_norm': 21.66449783007457, 'learning_rate': 9.062995293734562e-06, 'epoch': 0.28}
{'loss': 1.9465, 'grad_norm': 29.56779431458385, 'learning_rate': 9.04808056488853e-06, 'epoch': 0.28}
{'loss': 0.454, 'grad_norm': 16.605894926427272, 'learning_rate': 9.033060546187651e-06, 'epoch': 0.28}
{'loss': 1.4361, 'grad_norm': 25.641655085728075, 'learning_rate': 9.017935628299934e-06, 'epoch': 0.28}
{'loss': 1.125, 'grad_norm': 15.435479691874038, 'learning_rate': 9.002706204621802e-06, 'epoch': 0.29}
{'loss': 2.229, 'grad_norm': 36.18470093312055, 'learning_rate': 8.987372671267856e-06, 'epoch': 0.29}
{'loss': 0.9142, 'grad_norm': 19.05642716135774, 'learning_rate': 8.971935427060563e-06, 'epoch': 0.29}
{'loss': 1.8371, 'grad_norm': 27.864233707868966, 'learning_rate': 8.956394873519903e-06, 'epoch': 0.29}
{'loss': 1.6997, 'grad_norm': 24.14724771103937, 'learning_rate': 8.940751414852904e-06, 'epoch': 0.29}
{'loss': 1.6923, 'grad_norm': 23.76388802780419, 'learning_rate': 8.92500545794314e-06, 'epoch': 0.29}
{'loss': 1.8879, 'grad_norm': 16.36839819566419, 'learning_rate': 8.90915741234015e-06, 'epoch': 0.29}
{'loss': 1.1689, 'grad_norm': 27.952855187380475, 'learning_rate': 8.893207690248776e-06, 'epoch': 0.3}
{'loss': 1.1942, 'grad_norm': 22.907145837599412, 'learning_rate': 8.877156706518453e-06, 'epoch': 0.3}
{'loss': 0.837, 'grad_norm': 18.83078150986023, 'learning_rate': 8.861004878632409e-06, 'epoch': 0.3}
{'loss': 1.5503, 'grad_norm': 28.353929865874967, 'learning_rate': 8.84475262669681e-06, 'epoch': 0.3}
{'loss': 1.2942, 'grad_norm': 23.272902788031086, 'learning_rate': 8.82840037342984e-06, 'epoch': 0.3}
{'loss': 1.2638, 'grad_norm': 29.711781352284174, 'learning_rate': 8.811948544150693e-06, 'epoch': 0.3}
{'loss': 1.1455, 'grad_norm': 17.862310931024567, 'learning_rate': 8.795397566768518e-06, 'epoch': 0.31}
{'loss': 1.5546, 'grad_norm': 20.19395660443704, 'learning_rate': 8.778747871771293e-06, 'epoch': 0.31}
{'loss': 1.2123, 'grad_norm': 20.608559302725293, 'learning_rate': 8.761999892214619e-06, 'epoch': 0.31}
{'loss': 1.5536, 'grad_norm': 18.420486712547206, 'learning_rate': 8.745154063710464e-06, 'epoch': 0.31}
{'loss': 0.9658, 'grad_norm': 17.457932873681365, 'learning_rate': 8.728210824415829e-06, 'epoch': 0.31}
{'loss': 1.4344, 'grad_norm': 21.963034655148505, 'learning_rate': 8.71117061502135e-06, 'epoch': 0.31}
{'loss': 0.5663, 'grad_norm': 15.040294884514756, 'learning_rate': 8.694033878739842e-06, 'epoch': 0.31}
{'loss': 0.5138, 'grad_norm': 15.550776664395745, 'learning_rate': 8.676801061294764e-06, 'epoch': 0.32}
{'loss': 2.2152, 'grad_norm': 27.46895777730648, 'learning_rate': 8.659472610908628e-06, 'epoch': 0.32}
{'loss': 0.5931, 'grad_norm': 19.113450741489324, 'learning_rate': 8.642048978291347e-06, 'epoch': 0.32}
{'loss': 1.0487, 'grad_norm': 14.371520119365876, 'learning_rate': 8.624530616628502e-06, 'epoch': 0.32}
{'loss': 1.3237, 'grad_norm': 20.636088858183584, 'learning_rate': 8.60691798156956e-06, 'epoch': 0.32}
{'loss': 1.2598, 'grad_norm': 24.728743205192284, 'learning_rate': 8.589211531216026e-06, 'epoch': 0.32}
{'loss': 0.6793, 'grad_norm': 16.952662591015706, 'learning_rate': 8.571411726109518e-06, 'epoch': 0.32}
{'loss': 0.9883, 'grad_norm': 18.21105580901994, 'learning_rate': 8.553519029219803e-06, 'epoch': 0.33}
{'loss': 1.3485, 'grad_norm': 21.40042820803466, 'learning_rate': 8.535533905932739e-06, 'epoch': 0.33}
{'loss': 1.6957, 'grad_norm': 24.762074189498538, 'learning_rate': 8.517456824038179e-06, 'epoch': 0.33}
{'loss': 2.5403, 'grad_norm': 30.10202846654204, 'learning_rate': 8.49928825371781e-06, 'epoch': 0.33}
{'loss': 0.8605, 'grad_norm': 16.620911570195684, 'learning_rate': 8.481028667532907e-06, 'epoch': 0.33}
{'loss': 1.464, 'grad_norm': 19.649161809987266, 'learning_rate': 8.46267854041206e-06, 'epoch': 0.33}
{'loss': 0.9964, 'grad_norm': 20.150207555045903, 'learning_rate': 8.444238349638804e-06, 'epoch': 0.33}
{'loss': 1.1558, 'grad_norm': 15.146949812350597, 'learning_rate': 8.425708574839221e-06, 'epoch': 0.34}
{'loss': 2.0222, 'grad_norm': 25.38053551810364, 'learning_rate': 8.407089697969458e-06, 'epoch': 0.34}
{'loss': 1.0249, 'grad_norm': 19.891714262607614, 'learning_rate': 8.388382203303181e-06, 'epoch': 0.34}
{'loss': 1.2701, 'grad_norm': 21.156428532434752, 'learning_rate': 8.369586577419e-06, 'epoch': 0.34}
{'loss': 0.7755, 'grad_norm': 19.644409894428115, 'learning_rate': 8.3507033091878e-06, 'epoch': 0.34}
{'loss': 0.8295, 'grad_norm': 14.091848446915794, 'learning_rate': 8.331732889760021e-06, 'epoch': 0.34}
{'loss': 0.8751, 'grad_norm': 21.35041984955075, 'learning_rate': 8.312675812552898e-06, 'epoch': 0.34}
{'loss': 0.9322, 'grad_norm': 16.018671583203126, 'learning_rate': 8.293532573237616e-06, 'epoch': 0.35}
{'loss': 0.6659, 'grad_norm': 17.862800072037363, 'learning_rate': 8.274303669726427e-06, 'epoch': 0.35}
{'loss': 1.3132, 'grad_norm': 19.905576731430543, 'learning_rate': 8.25498960215968e-06, 'epoch': 0.35}
{'loss': 1.6165, 'grad_norm': 19.346045775802235, 'learning_rate': 8.235590872892837e-06, 'epoch': 0.35}
{'loss': 0.34, 'grad_norm': 13.679118161410653, 'learning_rate': 8.216107986483395e-06, 'epoch': 0.35}
{'loss': 0.5468, 'grad_norm': 14.069610166358396, 'learning_rate': 8.196541449677758e-06, 'epoch': 0.35}
{'loss': 1.1219, 'grad_norm': 20.957940397088695, 'learning_rate': 8.176891771398069e-06, 'epoch': 0.35}
{'loss': 1.1884, 'grad_norm': 16.531151807249067, 'learning_rate': 8.157159462728956e-06, 'epoch': 0.36}
{'loss': 1.7603, 'grad_norm': 24.410479307888902, 'learning_rate': 8.13734503690426e-06, 'epoch': 0.36}
{'loss': 1.298, 'grad_norm': 22.334540006013935, 'learning_rate': 8.117449009293668e-06, 'epoch': 0.36}
{'loss': 0.4978, 'grad_norm': 19.632792836421647, 'learning_rate': 8.097471897389316e-06, 'epoch': 0.36}
{'loss': 1.1705, 'grad_norm': 18.71904600570488, 'learning_rate': 8.077414220792328e-06, 'epoch': 0.36}
{'loss': 1.5108, 'grad_norm': 18.606243283932585, 'learning_rate': 8.057276501199301e-06, 'epoch': 0.36}
{'loss': 1.1714, 'grad_norm': 16.618491203094067, 'learning_rate': 8.03705926238874e-06, 'epoch': 0.36}
{'loss': 1.5694, 'grad_norm': 18.05690405964982, 'learning_rate': 8.016763030207422e-06, 'epoch': 0.37}
{'loss': 1.4344, 'grad_norm': 23.845684988195345, 'learning_rate': 7.996388332556735e-06, 'epoch': 0.37}
{'loss': 1.5383, 'grad_norm': 25.65029944248688, 'learning_rate': 7.97593569937894e-06, 'epoch': 0.37}
{'loss': 1.7407, 'grad_norm': 23.494550014493036, 'learning_rate': 7.955405662643384e-06, 'epoch': 0.37}
{'loss': 1.0405, 'grad_norm': 18.841881752994922, 'learning_rate': 7.934798756332666e-06, 'epoch': 0.37}
{'loss': 1.7521, 'grad_norm': 22.90693423861749, 'learning_rate': 7.914115516428751e-06, 'epoch': 0.37}
{'loss': 0.496, 'grad_norm': 14.190130064506697, 'learning_rate': 7.89335648089903e-06, 'epoch': 0.38}
{'loss': 1.3218, 'grad_norm': 19.744997591553446, 'learning_rate': 7.872522189682318e-06, 'epoch': 0.38}
{'loss': 0.9404, 'grad_norm': 18.102702222943083, 'learning_rate': 7.851613184674821e-06, 'epoch': 0.38}
{'loss': 1.4406, 'grad_norm': 19.901941306256962, 'learning_rate': 7.830630009716038e-06, 'epoch': 0.38}
{'loss': 0.9572, 'grad_norm': 17.270084490928717, 'learning_rate': 7.809573210574615e-06, 'epoch': 0.38}
{'loss': 0.3978, 'grad_norm': 12.975063593778057, 'learning_rate': 7.788443334934148e-06, 'epoch': 0.38}
{'loss': 0.8385, 'grad_norm': 14.829103850826073, 'learning_rate': 7.76724093237894e-06, 'epoch': 0.38}
{'loss': 1.4582, 'grad_norm': 23.09158271022159, 'learning_rate': 7.745966554379708e-06, 'epoch': 0.39}
{'loss': 1.1089, 'grad_norm': 26.205316906878735, 'learning_rate': 7.72462075427924e-06, 'epoch': 0.39}
{'loss': 1.6134, 'grad_norm': 21.001881199156752, 'learning_rate': 7.703204087277989e-06, 'epoch': 0.39}
{'loss': 0.4401, 'grad_norm': 15.413296206183226, 'learning_rate': 7.681717110419657e-06, 'epoch': 0.39}
{'loss': 0.9331, 'grad_norm': 16.81176406720174, 'learning_rate': 7.660160382576683e-06, 'epoch': 0.39}
{'loss': 0.8877, 'grad_norm': 20.023361522653982, 'learning_rate': 7.638534464435725e-06, 'epoch': 0.39}
{'loss': 0.9529, 'grad_norm': 17.737535778809445, 'learning_rate': 7.616839918483061e-06, 'epoch': 0.39}
{'loss': 1.116, 'grad_norm': 17.559511883524664, 'learning_rate': 7.5950773089899695e-06, 'epoch': 0.4}
{'loss': 1.0137, 'grad_norm': 20.297530001426047, 'learning_rate': 7.573247201998051e-06, 'epoch': 0.4}
{'loss': 0.9353, 'grad_norm': 14.457892344713173, 'learning_rate': 7.5513501653045e-06, 'epoch': 0.4}
{'loss': 0.9295, 'grad_norm': 14.83178426205685, 'learning_rate': 7.529386768447342e-06, 'epoch': 0.4}
{'loss': 0.4077, 'grad_norm': 14.771296749971578, 'learning_rate': 7.507357582690622e-06, 'epoch': 0.4}
{'loss': 1.1381, 'grad_norm': 17.822184487431304, 'learning_rate': 7.485263181009539e-06, 'epoch': 0.4}
{'loss': 1.0572, 'grad_norm': 15.626487241591951, 'learning_rate': 7.463104138075548e-06, 'epoch': 0.4}
{'loss': 1.416, 'grad_norm': 20.510275407930223, 'learning_rate': 7.440881030241407e-06, 'epoch': 0.41}
{'loss': 0.419, 'grad_norm': 12.911924651154896, 'learning_rate': 7.4185944355261996e-06, 'epoch': 0.41}
{'loss': 1.7436, 'grad_norm': 25.008402822538038, 'learning_rate': 7.396244933600285e-06, 'epoch': 0.41}
{'loss': 0.7945, 'grad_norm': 21.735452124717284, 'learning_rate': 7.37383310577023e-06, 'epoch': 0.41}
{'loss': 1.4594, 'grad_norm': 22.017313710946617, 'learning_rate': 7.351359534963684e-06, 'epoch': 0.41}
{'loss': 1.367, 'grad_norm': 21.78957634566328, 'learning_rate': 7.328824805714228e-06, 'epoch': 0.41}
{'loss': 1.2536, 'grad_norm': 17.569863085377314, 'learning_rate': 7.306229504146154e-06, 'epoch': 0.41}
{'loss': 0.9173, 'grad_norm': 17.84505132163913, 'learning_rate': 7.283574217959234e-06, 'epoch': 0.42}
{'loss': 1.0102, 'grad_norm': 15.792281398289923, 'learning_rate': 7.260859536413429e-06, 'epoch': 0.42}
{'loss': 0.9883, 'grad_norm': 18.33958436850826, 'learning_rate': 7.238086050313563e-06, 'epoch': 0.42}
{'loss': 1.687, 'grad_norm': 28.365875583137864, 'learning_rate': 7.215254351993957e-06, 'epoch': 0.42}
{'loss': 1.0559, 'grad_norm': 24.92313565159841, 'learning_rate': 7.192365035303014e-06, 'epoch': 0.42}
{'loss': 1.5255, 'grad_norm': 21.138781641146114, 'learning_rate': 7.169418695587791e-06, 'epoch': 0.42}
{'loss': 0.7932, 'grad_norm': 19.78791525559841, 'learning_rate': 7.146415929678498e-06, 'epoch': 0.42}
{'loss': 1.0395, 'grad_norm': 16.813799758107116, 'learning_rate': 7.123357335872982e-06, 'epoch': 0.43}
{'loss': 0.7329, 'grad_norm': 15.00914563812138, 'learning_rate': 7.100243513921162e-06, 'epoch': 0.43}
{'loss': 0.9963, 'grad_norm': 16.965762484622413, 'learning_rate': 7.0770750650094335e-06, 'epoch': 0.43}
{'loss': 1.1862, 'grad_norm': 17.61947612115901, 'learning_rate': 7.053852591745025e-06, 'epoch': 0.43}
{'loss': 0.2971, 'grad_norm': 9.244576210212045, 'learning_rate': 7.0305766981403365e-06, 'epoch': 0.43}
{'loss': 0.7481, 'grad_norm': 17.70869025710713, 'learning_rate': 7.007247989597213e-06, 'epoch': 0.43}
{'loss': 1.6135, 'grad_norm': 21.0862298670073, 'learning_rate': 6.983867072891213e-06, 'epoch': 0.44}
{'loss': 1.1572, 'grad_norm': 19.902515802417515, 'learning_rate': 6.9604345561558175e-06, 'epoch': 0.44}
{'loss': 0.8659, 'grad_norm': 26.65116907291325, 'learning_rate': 6.936951048866616e-06, 'epoch': 0.44}
{'loss': 0.3869, 'grad_norm': 11.341782650775148, 'learning_rate': 6.913417161825449e-06, 'epoch': 0.44}
{'loss': 1.1999, 'grad_norm': 18.864256140554954, 'learning_rate': 6.889833507144534e-06, 'epoch': 0.44}
{'loss': 1.348, 'grad_norm': 19.271037171356276, 'learning_rate': 6.866200698230527e-06, 'epoch': 0.44}
{'loss': 1.4551, 'grad_norm': 23.496143759764234, 'learning_rate': 6.842519349768582e-06, 'epoch': 0.44}
{'loss': 1.0627, 'grad_norm': 19.099723328743252, 'learning_rate': 6.818790077706358e-06, 'epoch': 0.45}
{'loss': 1.0892, 'grad_norm': 18.00764312739094, 'learning_rate': 6.7950134992379935e-06, 'epoch': 0.45}
{'loss': 1.1347, 'grad_norm': 20.59312614770118, 'learning_rate': 6.7711902327880665e-06, 'epoch': 0.45}
{'loss': 1.9665, 'grad_norm': 19.30054180095403, 'learning_rate': 6.747320897995493e-06, 'epoch': 0.45}
{'loss': 1.3341, 'grad_norm': 22.08145567353581, 'learning_rate': 6.723406115697422e-06, 'epoch': 0.45}
{'loss': 1.4455, 'grad_norm': 18.49025667338408, 'learning_rate': 6.699446507913083e-06, 'epoch': 0.45}
{'loss': 1.7187, 'grad_norm': 23.486187839117175, 'learning_rate': 6.6754426978276146e-06, 'epoch': 0.45}
{'loss': 1.5154, 'grad_norm': 19.157272517096754, 'learning_rate': 6.651395309775837e-06, 'epoch': 0.46}
{'loss': 0.3249, 'grad_norm': 12.984798469824002, 'learning_rate': 6.627304969226034e-06, 'epoch': 0.46}
{'loss': 0.9974, 'grad_norm': 22.721626222226995, 'learning_rate': 6.6031723027636775e-06, 'epoch': 0.46}
{'loss': 2.3309, 'grad_norm': 25.957402304464782, 'learning_rate': 6.578997938075126e-06, 'epoch': 0.46}
{'loss': 1.2202, 'grad_norm': 19.691619480475488, 'learning_rate': 6.554782503931298e-06, 'epoch': 0.46}
{'loss': 1.2716, 'grad_norm': 16.2308821396625, 'learning_rate': 6.5305266301713275e-06, 'epoch': 0.46}
{'loss': 1.2945, 'grad_norm': 22.230820455577938, 'learning_rate': 6.5062309476861714e-06, 'epoch': 0.46}
{'loss': 1.4281, 'grad_norm': 16.637460029064886, 'learning_rate': 6.4818960884022084e-06, 'epoch': 0.47}
{'loss': 0.4048, 'grad_norm': 11.238616210257042, 'learning_rate': 6.457522685264793e-06, 'epoch': 0.47}
{'loss': 1.0551, 'grad_norm': 18.155964452827565, 'learning_rate': 6.433111372221805e-06, 'epoch': 0.47}
{'loss': 1.4445, 'grad_norm': 20.26769992907612, 'learning_rate': 6.408662784207149e-06, 'epoch': 0.47}
{'loss': 0.673, 'grad_norm': 17.378237150121574, 'learning_rate': 6.384177557124247e-06, 'epoch': 0.47}
{'loss': 1.4898, 'grad_norm': 32.636482265011395, 'learning_rate': 6.359656327829498e-06, 'epoch': 0.47}
{'loss': 0.7193, 'grad_norm': 18.44614154613564, 'learning_rate': 6.335099734115709e-06, 'epoch': 0.47}
{'loss': 1.2595, 'grad_norm': 20.73013400154072, 'learning_rate': 6.310508414695511e-06, 'epoch': 0.48}
{'loss': 0.7146, 'grad_norm': 15.031411968146573, 'learning_rate': 6.285883009184745e-06, 'epoch': 0.48}
{'loss': 1.397, 'grad_norm': 18.393124820876977, 'learning_rate': 6.261224158085826e-06, 'epoch': 0.48}
{'loss': 0.921, 'grad_norm': 17.412040517885718, 'learning_rate': 6.236532502771078e-06, 'epoch': 0.48}
{'loss': 0.4148, 'grad_norm': 12.94883780919988, 'learning_rate': 6.211808685466063e-06, 'epoch': 0.48}
{'loss': 1.4598, 'grad_norm': 20.62203491576625, 'learning_rate': 6.187053349232865e-06, 'epoch': 0.48}
{'loss': 1.1239, 'grad_norm': 20.71212906723983, 'learning_rate': 6.162267137953374e-06, 'epoch': 0.48}
{'loss': 1.1183, 'grad_norm': 22.827195369585695, 'learning_rate': 6.137450696312534e-06, 'epoch': 0.49}
{'loss': 1.005, 'grad_norm': 18.179869270597123, 'learning_rate': 6.112604669781572e-06, 'epoch': 0.49}
{'loss': 1.76, 'grad_norm': 26.995457612207204, 'learning_rate': 6.0877297046012176e-06, 'epoch': 0.49}
{'loss': 1.3181, 'grad_norm': 22.645062709061104, 'learning_rate': 6.062826447764883e-06, 'epoch': 0.49}
{'loss': 1.9215, 'grad_norm': 28.23536551138337, 'learning_rate': 6.037895547001851e-06, 'epoch': 0.49}
{'loss': 1.2284, 'grad_norm': 18.042670994650933, 'learning_rate': 6.012937650760406e-06, 'epoch': 0.49}
{'loss': 0.7353, 'grad_norm': 17.032444308662324, 'learning_rate': 5.987953408190989e-06, 'epoch': 0.49}
{'loss': 0.8521, 'grad_norm': 15.394406215537531, 'learning_rate': 5.962943469129303e-06, 'epoch': 0.5}
{'loss': 0.8733, 'grad_norm': 19.075457220820002, 'learning_rate': 5.937908484079408e-06, 'epoch': 0.5}
{'loss': 2.3868, 'grad_norm': 21.17227123239434, 'learning_rate': 5.91284910419681e-06, 'epoch': 0.5}
{'loss': 1.4684, 'grad_norm': 27.052397991692825, 'learning_rate': 5.887765981271518e-06, 'epoch': 0.5}
{'loss': 0.3566, 'grad_norm': 11.535561134220503, 'learning_rate': 5.862659767711094e-06, 'epoch': 0.5}
{'loss': 1.2172, 'grad_norm': 22.911783459414252, 'learning_rate': 5.837531116523683e-06, 'epoch': 0.5}
{'loss': 1.033, 'grad_norm': 25.891021124975236, 'learning_rate': 5.812380681301031e-06, 'epoch': 0.51}
{'loss': 2.1205, 'grad_norm': 28.057349380616333, 'learning_rate': 5.787209116201478e-06, 'epoch': 0.51}
{'loss': 1.5967, 'grad_norm': 20.822660477990155, 'learning_rate': 5.762017075932952e-06, 'epoch': 0.51}
{'loss': 0.8282, 'grad_norm': 18.191459907513963, 'learning_rate': 5.736805215735937e-06, 'epoch': 0.51}
{'loss': 1.8741, 'grad_norm': 23.46232272909893, 'learning_rate': 5.711574191366427e-06, 'epoch': 0.51}
[INFO|configuration_utils.py:491] 2025-12-19 01:53:33,230 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/config.json
[INFO|configuration_utils.py:757] 2025-12-19 01:53:33,231 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/generation_config.json
[INFO|modeling_utils.py:4181] 2025-12-19 01:53:36,103 >> Model weights saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/model.safetensors
[INFO|tokenization_utils_base.py:2421] 2025-12-19 01:53:36,105 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 01:53:36,106 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 01:53:36,106 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/special_tokens_map.json
/home/seohyun/.conda/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
[2025-12-19 01:53:36,237] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step350 is about to be saved!
[2025-12-19 01:53:36,317] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-19 01:53:36,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-19 01:53:36,639] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-19 01:53:36,661] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-19 01:53:44,313] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-19 01:53:44,314] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/global_step350/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-19 01:53:46,513] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step350 is ready now!
[INFO|image_processing_base.py:253] 2025-12-19 01:53:46,523 >> Image processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-12-19 01:53:46,532 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 01:53:46,534 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 01:53:46,541 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-12-19 01:53:46,742 >> Video processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-12-19 01:53:46,754 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350/chat_template.jinja
                                                                                                    
{'loss': 0.8433, 'grad_norm': 15.507899987014603, 'learning_rate': 5.686324659078875e-06, 'epoch': 0.51}
{'loss': 0.9809, 'grad_norm': 19.161463914527282, 'learning_rate': 5.66105727560912e-06, 'epoch': 0.51}
{'loss': 1.5984, 'grad_norm': 22.188512800744302, 'learning_rate': 5.63577269815731e-06, 'epoch': 0.52}
{'loss': 0.874, 'grad_norm': 14.158229030234056, 'learning_rate': 5.6104715843708e-06, 'epoch': 0.52}
{'loss': 0.3298, 'grad_norm': 11.082748396592768, 'learning_rate': 5.585154592327059e-06, 'epoch': 0.52}
{'loss': 1.4169, 'grad_norm': 21.72499733716384, 'learning_rate': 5.559822380516539e-06, 'epoch': 0.52}
{'loss': 0.6242, 'grad_norm': 16.58914469770399, 'learning_rate': 5.534475607825566e-06, 'epoch': 0.52}
{'loss': 1.3048, 'grad_norm': 24.24826177909512, 'learning_rate': 5.509114933519179e-06, 'epoch': 0.52}
{'loss': 1.3907, 'grad_norm': 21.607618782235427, 'learning_rate': 5.4837410172240035e-06, 'epoch': 0.52}
{'loss': 1.4189, 'grad_norm': 23.612300492926998, 'learning_rate': 5.458354518911086e-06, 'epoch': 0.53}
{'loss': 1.365, 'grad_norm': 18.532789330713154, 'learning_rate': 5.43295609887873e-06, 'epoch': 0.53}
{'loss': 0.9569, 'grad_norm': 17.04330998009103, 'learning_rate': 5.4075464177353165e-06, 'epoch': 0.53}
{'loss': 0.465, 'grad_norm': 16.04398253097706, 'learning_rate': 5.38212613638213e-06, 'epoch': 0.53}
{'loss': 1.4003, 'grad_norm': 22.758110435276027, 'learning_rate': 5.356695915996162e-06, 'epoch': 0.53}
{'loss': 0.8608, 'grad_norm': 12.455663351105814, 'learning_rate': 5.33125641801292e-06, 'epoch': 0.53}
{'loss': 0.3208, 'grad_norm': 11.611172439099677, 'learning_rate': 5.3058083041092145e-06, 'epoch': 0.53}
{'loss': 1.1469, 'grad_norm': 17.30886435818207, 'learning_rate': 5.2803522361859596e-06, 'epoch': 0.54}
{'loss': 1.3529, 'grad_norm': 16.853849930548762, 'learning_rate': 5.25488887635095e-06, 'epoch': 0.54}
{'loss': 1.3013, 'grad_norm': 15.149367835230201, 'learning_rate': 5.229418886901644e-06, 'epoch': 0.54}
{'loss': 1.0664, 'grad_norm': 17.592588951023153, 'learning_rate': 5.2039429303079294e-06, 'epoch': 0.54}
{'loss': 0.4951, 'grad_norm': 13.503818852223693, 'learning_rate': 5.178461669194903e-06, 'epoch': 0.54}
{'loss': 0.9795, 'grad_norm': 15.382902368153106, 'learning_rate': 5.152975766325631e-06, 'epoch': 0.54}
{'loss': 0.3795, 'grad_norm': 9.925193149352838, 'learning_rate': 5.127485884583911e-06, 'epoch': 0.54}
{'loss': 1.6336, 'grad_norm': 24.49931159283931, 'learning_rate': 5.101992686957028e-06, 'epoch': 0.55}
{'loss': 1.1742, 'grad_norm': 18.691403819471915, 'learning_rate': 5.076496836518513e-06, 'epoch': 0.55}
{'loss': 1.6585, 'grad_norm': 24.989720787766583, 'learning_rate': 5.050998996410899e-06, 'epoch': 0.55}
{'loss': 0.3608, 'grad_norm': 14.19634190211313, 'learning_rate': 5.025499829828467e-06, 'epoch': 0.55}
{'loss': 0.557, 'grad_norm': 13.978887724077273, 'learning_rate': 5e-06, 'epoch': 0.55}
{'loss': 0.8595, 'grad_norm': 16.66237964307792, 'learning_rate': 4.974500170171534e-06, 'epoch': 0.55}
{'loss': 1.1579, 'grad_norm': 26.931678104302428, 'learning_rate': 4.949001003589102e-06, 'epoch': 0.55}
{'loss': 0.9363, 'grad_norm': 14.585037456873046, 'learning_rate': 4.9235031634814875e-06, 'epoch': 0.56}
{'loss': 0.6095, 'grad_norm': 14.516779433060538, 'learning_rate': 4.898007313042975e-06, 'epoch': 0.56}
{'loss': 1.3366, 'grad_norm': 19.133617500684124, 'learning_rate': 4.872514115416091e-06, 'epoch': 0.56}
{'loss': 1.4854, 'grad_norm': 19.65883589085307, 'learning_rate': 4.84702423367437e-06, 'epoch': 0.56}
{'loss': 1.9655, 'grad_norm': 21.714853401334896, 'learning_rate': 4.821538330805098e-06, 'epoch': 0.56}
{'loss': 0.7274, 'grad_norm': 14.338275098569042, 'learning_rate': 4.796057069692073e-06, 'epoch': 0.56}
{'loss': 1.5616, 'grad_norm': 20.394663197814385, 'learning_rate': 4.770581113098358e-06, 'epoch': 0.56}
{'loss': 0.6334, 'grad_norm': 16.903831952608332, 'learning_rate': 4.74511112364905e-06, 'epoch': 0.57}
{'loss': 1.0091, 'grad_norm': 17.624494428095332, 'learning_rate': 4.719647763814041e-06, 'epoch': 0.57}
{'loss': 1.5443, 'grad_norm': 27.557542378266238, 'learning_rate': 4.694191695890788e-06, 'epoch': 0.57}
{'loss': 0.7996, 'grad_norm': 12.691150612945007, 'learning_rate': 4.6687435819870825e-06, 'epoch': 0.57}
{'loss': 1.2124, 'grad_norm': 22.64944448047408, 'learning_rate': 4.643304084003839e-06, 'epoch': 0.57}
{'loss': 0.7668, 'grad_norm': 17.761817686819317, 'learning_rate': 4.617873863617872e-06, 'epoch': 0.57}
{'loss': 1.9863, 'grad_norm': 29.595093716671983, 'learning_rate': 4.592453582264684e-06, 'epoch': 0.58}
{'loss': 0.6387, 'grad_norm': 16.63198805979444, 'learning_rate': 4.567043901121271e-06, 'epoch': 0.58}
{'loss': 1.7815, 'grad_norm': 23.023326458636713, 'learning_rate': 4.541645481088914e-06, 'epoch': 0.58}
{'loss': 1.5515, 'grad_norm': 17.374967900833884, 'learning_rate': 4.516258982775997e-06, 'epoch': 0.58}
{'loss': 0.2874, 'grad_norm': 12.704752601044458, 'learning_rate': 4.4908850664808245e-06, 'epoch': 0.58}
{'loss': 0.406, 'grad_norm': 14.74558281815974, 'learning_rate': 4.465524392174437e-06, 'epoch': 0.58}
{'loss': 1.1339, 'grad_norm': 31.79101055439129, 'learning_rate': 4.4401776194834615e-06, 'epoch': 0.58}
{'loss': 0.3619, 'grad_norm': 11.86510818127108, 'learning_rate': 4.414845407672943e-06, 'epoch': 0.59}
{'loss': 1.7008, 'grad_norm': 18.379921265021093, 'learning_rate': 4.389528415629201e-06, 'epoch': 0.59}
{'loss': 1.4913, 'grad_norm': 21.34615119145132, 'learning_rate': 4.364227301842691e-06, 'epoch': 0.59}
{'loss': 0.5176, 'grad_norm': 15.496708112258602, 'learning_rate': 4.33894272439088e-06, 'epoch': 0.59}
{'loss': 0.5892, 'grad_norm': 16.135290161482917, 'learning_rate': 4.313675340921128e-06, 'epoch': 0.59}
{'loss': 2.1087, 'grad_norm': 33.73844550206349, 'learning_rate': 4.2884258086335755e-06, 'epoch': 0.59}
{'loss': 0.8803, 'grad_norm': 17.485563308954863, 'learning_rate': 4.263194784264065e-06, 'epoch': 0.59}
{'loss': 0.7625, 'grad_norm': 12.1461973426929, 'learning_rate': 4.23798292406705e-06, 'epoch': 0.6}
{'loss': 1.0583, 'grad_norm': 16.68261401798399, 'learning_rate': 4.212790883798524e-06, 'epoch': 0.6}
{'loss': 0.5341, 'grad_norm': 15.677806444387402, 'learning_rate': 4.187619318698971e-06, 'epoch': 0.6}
{'loss': 2.094, 'grad_norm': 28.47974632278838, 'learning_rate': 4.162468883476319e-06, 'epoch': 0.6}
{'loss': 1.5131, 'grad_norm': 21.56222366481881, 'learning_rate': 4.137340232288908e-06, 'epoch': 0.6}
{'loss': 1.3524, 'grad_norm': 23.05990158780403, 'learning_rate': 4.1122340187284845e-06, 'epoch': 0.6}
{'loss': 1.8783, 'grad_norm': 27.07805016267877, 'learning_rate': 4.087150895803192e-06, 'epoch': 0.6}
{'loss': 1.5343, 'grad_norm': 24.57571187631209, 'learning_rate': 4.062091515920595e-06, 'epoch': 0.61}
{'loss': 1.0943, 'grad_norm': 21.135403146755664, 'learning_rate': 4.0370565308706986e-06, 'epoch': 0.61}
{'loss': 1.2565, 'grad_norm': 20.658221139908818, 'learning_rate': 4.012046591809012e-06, 'epoch': 0.61}
{'loss': 1.3614, 'grad_norm': 19.299116745717324, 'learning_rate': 3.987062349239596e-06, 'epoch': 0.61}
{'loss': 1.3477, 'grad_norm': 18.78641203373436, 'learning_rate': 3.9621044529981515e-06, 'epoch': 0.61}
{'loss': 1.0115, 'grad_norm': 22.257630246100472, 'learning_rate': 3.937173552235117e-06, 'epoch': 0.61}
{'loss': 1.0152, 'grad_norm': 14.493401230450084, 'learning_rate': 3.912270295398785e-06, 'epoch': 0.61}
{'loss': 0.8859, 'grad_norm': 13.964534659103565, 'learning_rate': 3.887395330218429e-06, 'epoch': 0.62}
{'loss': 0.8037, 'grad_norm': 13.304898156729282, 'learning_rate': 3.862549303687468e-06, 'epoch': 0.62}
{'loss': 1.5275, 'grad_norm': 19.732090695545775, 'learning_rate': 3.837732862046627e-06, 'epoch': 0.62}
{'loss': 0.2429, 'grad_norm': 9.192329424457109, 'learning_rate': 3.8129466507671365e-06, 'epoch': 0.62}
{'loss': 1.3907, 'grad_norm': 23.62064555694237, 'learning_rate': 3.7881913145339387e-06, 'epoch': 0.62}
{'loss': 0.3531, 'grad_norm': 10.849191750287753, 'learning_rate': 3.7634674972289227e-06, 'epoch': 0.62}
{'loss': 0.6174, 'grad_norm': 14.488642812054486, 'learning_rate': 3.738775841914175e-06, 'epoch': 0.62}
{'loss': 0.915, 'grad_norm': 15.079833878268065, 'learning_rate': 3.7141169908152562e-06, 'epoch': 0.63}
{'loss': 1.6738, 'grad_norm': 23.512068268827655, 'learning_rate': 3.689491585304491e-06, 'epoch': 0.63}
{'loss': 1.306, 'grad_norm': 19.318430208466662, 'learning_rate': 3.6649002658842925e-06, 'epoch': 0.63}
{'loss': 0.6898, 'grad_norm': 15.69941340730072, 'learning_rate': 3.640343672170503e-06, 'epoch': 0.63}
{'loss': 1.2413, 'grad_norm': 17.843640786020693, 'learning_rate': 3.6158224428757538e-06, 'epoch': 0.63}
{'loss': 1.3461, 'grad_norm': 17.431042816180067, 'learning_rate': 3.5913372157928515e-06, 'epoch': 0.63}
{'loss': 0.2913, 'grad_norm': 11.95847583381977, 'learning_rate': 3.5668886277781955e-06, 'epoch': 0.64}
{'loss': 0.9127, 'grad_norm': 18.729670420984586, 'learning_rate': 3.5424773147352085e-06, 'epoch': 0.64}
{'loss': 1.1581, 'grad_norm': 23.255952157781408, 'learning_rate': 3.5181039115977945e-06, 'epoch': 0.64}
{'loss': 0.313, 'grad_norm': 9.41448550558788, 'learning_rate': 3.4937690523138302e-06, 'epoch': 0.64}
{'loss': 1.0233, 'grad_norm': 18.62440493895336, 'learning_rate': 3.469473369828674e-06, 'epoch': 0.64}
{'loss': 0.3488, 'grad_norm': 15.350482963810057, 'learning_rate': 3.4452174960687033e-06, 'epoch': 0.64}
{'loss': 0.291, 'grad_norm': 12.153902714971775, 'learning_rate': 3.4210020619248762e-06, 'epoch': 0.64}
{'loss': 0.3379, 'grad_norm': 13.523426188820235, 'learning_rate': 3.3968276972363224e-06, 'epoch': 0.65}
{'loss': 0.3603, 'grad_norm': 12.339656333798633, 'learning_rate': 3.372695030773966e-06, 'epoch': 0.65}
{'loss': 0.2562, 'grad_norm': 12.924056258862548, 'learning_rate': 3.3486046902241663e-06, 'epoch': 0.65}
{'loss': 1.1789, 'grad_norm': 19.880994860441778, 'learning_rate': 3.324557302172389e-06, 'epoch': 0.65}
{'loss': 0.3527, 'grad_norm': 10.894044025477415, 'learning_rate': 3.3005534920869175e-06, 'epoch': 0.65}
{'loss': 1.5373, 'grad_norm': 19.07127835341922, 'learning_rate': 3.27659388430258e-06, 'epoch': 0.65}
{'loss': 0.8134, 'grad_norm': 16.5159904825139, 'learning_rate': 3.252679102004509e-06, 'epoch': 0.65}
{'loss': 1.7602, 'grad_norm': 20.935015015500543, 'learning_rate': 3.2288097672119347e-06, 'epoch': 0.66}
{'loss': 1.0, 'grad_norm': 16.79340229859981, 'learning_rate': 3.204986500762006e-06, 'epoch': 0.66}
{'loss': 1.3705, 'grad_norm': 21.930275381021413, 'learning_rate': 3.1812099222936434e-06, 'epoch': 0.66}
{'loss': 1.2077, 'grad_norm': 19.059918140642882, 'learning_rate': 3.1574806502314206e-06, 'epoch': 0.66}
{'loss': 0.5811, 'grad_norm': 17.378007519136567, 'learning_rate': 3.133799301769475e-06, 'epoch': 0.66}
{'loss': 1.7129, 'grad_norm': 23.260013652557177, 'learning_rate': 3.110166492855468e-06, 'epoch': 0.66}
{'loss': 0.8714, 'grad_norm': 12.543253883269086, 'learning_rate': 3.0865828381745515e-06, 'epoch': 0.66}
{'loss': 0.8319, 'grad_norm': 15.809826228465115, 'learning_rate': 3.063048951133386e-06, 'epoch': 0.67}
{'loss': 0.7166, 'grad_norm': 15.408652201465918, 'learning_rate': 3.0395654438441833e-06, 'epoch': 0.67}
{'loss': 1.7704, 'grad_norm': 20.332213495916882, 'learning_rate': 3.016132927108787e-06, 'epoch': 0.67}
{'loss': 0.9297, 'grad_norm': 16.406816244263737, 'learning_rate': 2.992752010402789e-06, 'epoch': 0.67}
{'loss': 1.7476, 'grad_norm': 25.361842327178046, 'learning_rate': 2.9694233018596665e-06, 'epoch': 0.67}
{'loss': 0.7226, 'grad_norm': 16.060107653320006, 'learning_rate': 2.946147408254976e-06, 'epoch': 0.67}
{'loss': 1.5807, 'grad_norm': 21.400839579009503, 'learning_rate': 2.9229249349905686e-06, 'epoch': 0.67}
{'loss': 0.3155, 'grad_norm': 11.432265687476633, 'learning_rate': 2.8997564860788385e-06, 'epoch': 0.68}
{'loss': 0.8725, 'grad_norm': 16.87349147526827, 'learning_rate': 2.8766426641270197e-06, 'epoch': 0.68}
{'loss': 0.3142, 'grad_norm': 11.298183746774688, 'learning_rate': 2.8535840703215016e-06, 'epoch': 0.68}
{'loss': 0.3151, 'grad_norm': 11.697481012984552, 'learning_rate': 2.83058130441221e-06, 'epoch': 0.68}
{'loss': 0.8879, 'grad_norm': 15.510056213674131, 'learning_rate': 2.807634964696988e-06, 'epoch': 0.68}
{'loss': 1.9101, 'grad_norm': 31.91830662867049, 'learning_rate': 2.7847456480060476e-06, 'epoch': 0.68}
{'loss': 0.8387, 'grad_norm': 16.956242307816904, 'learning_rate': 2.761913949686438e-06, 'epoch': 0.68}
{'loss': 0.6915, 'grad_norm': 13.190457528204666, 'learning_rate': 2.7391404635865725e-06, 'epoch': 0.69}
{'loss': 1.4511, 'grad_norm': 22.075541388087814, 'learning_rate': 2.716425782040767e-06, 'epoch': 0.69}
{'loss': 0.5354, 'grad_norm': 14.619346121954086, 'learning_rate': 2.6937704958538483e-06, 'epoch': 0.69}
{'loss': 1.1843, 'grad_norm': 21.556595134585095, 'learning_rate': 2.671175194285773e-06, 'epoch': 0.69}
{'loss': 0.9132, 'grad_norm': 15.478344932835096, 'learning_rate': 2.648640465036316e-06, 'epoch': 0.69}
{'loss': 1.4292, 'grad_norm': 18.08732814418171, 'learning_rate': 2.6261668942297724e-06, 'epoch': 0.69}
{'loss': 0.3168, 'grad_norm': 13.165014851407559, 'learning_rate': 2.603755066399718e-06, 'epoch': 0.69}
{'loss': 0.9135, 'grad_norm': 19.58870646739033, 'learning_rate': 2.5814055644738013e-06, 'epoch': 0.7}
{'loss': 0.3589, 'grad_norm': 12.20023874708333, 'learning_rate': 2.559118969758595e-06, 'epoch': 0.7}
{'loss': 1.4495, 'grad_norm': 23.979429462929147, 'learning_rate': 2.5368958619244542e-06, 'epoch': 0.7}
{'loss': 1.3687, 'grad_norm': 22.90677839264691, 'learning_rate': 2.514736818990463e-06, 'epoch': 0.7}
{'loss': 0.8286, 'grad_norm': 17.39640992485432, 'learning_rate': 2.4926424173093785e-06, 'epoch': 0.7}
{'loss': 0.9153, 'grad_norm': 19.116930331634094, 'learning_rate': 2.470613231552661e-06, 'epoch': 0.7}
{'loss': 0.7811, 'grad_norm': 19.135237123404774, 'learning_rate': 2.448649834695503e-06, 'epoch': 0.71}
{'loss': 1.9109, 'grad_norm': 22.98100985411446, 'learning_rate': 2.4267527980019523e-06, 'epoch': 0.71}
{'loss': 1.403, 'grad_norm': 17.79719674680156, 'learning_rate': 2.4049226910100317e-06, 'epoch': 0.71}
{'loss': 0.7579, 'grad_norm': 17.688409027677782, 'learning_rate': 2.383160081516941e-06, 'epoch': 0.71}
{'loss': 1.0259, 'grad_norm': 10.331855429289423, 'learning_rate': 2.3614655355642758e-06, 'epoch': 0.71}
{'loss': 1.7547, 'grad_norm': 19.15208612021418, 'learning_rate': 2.339839617423318e-06, 'epoch': 0.71}
{'loss': 0.6691, 'grad_norm': 18.615489585906026, 'learning_rate': 2.3182828895803438e-06, 'epoch': 0.71}
{'loss': 1.0558, 'grad_norm': 16.16107911592973, 'learning_rate': 2.296795912722014e-06, 'epoch': 0.72}
{'loss': 1.6425, 'grad_norm': 22.108039766117596, 'learning_rate': 2.275379245720763e-06, 'epoch': 0.72}
{'loss': 0.2666, 'grad_norm': 11.231863623101702, 'learning_rate': 2.254033445620293e-06, 'epoch': 0.72}
{'loss': 0.5452, 'grad_norm': 15.704866699909042, 'learning_rate': 2.23275906762106e-06, 'epoch': 0.72}
{'loss': 1.3766, 'grad_norm': 19.94377631956469, 'learning_rate': 2.211556665065854e-06, 'epoch': 0.72}
{'loss': 1.2455, 'grad_norm': 17.815248326624875, 'learning_rate': 2.1904267894253854e-06, 'epoch': 0.72}
{'loss': 1.0785, 'grad_norm': 15.702859254461972, 'learning_rate': 2.169369990283963e-06, 'epoch': 0.72}
{'loss': 1.2295, 'grad_norm': 23.867364274080277, 'learning_rate': 2.148386815325179e-06, 'epoch': 0.73}
{'loss': 1.2387, 'grad_norm': 26.17338271652596, 'learning_rate': 2.1274778103176854e-06, 'epoch': 0.73}
{'loss': 1.0645, 'grad_norm': 17.064678300968946, 'learning_rate': 2.1066435191009717e-06, 'epoch': 0.73}
{'loss': 0.7064, 'grad_norm': 15.544935017939753, 'learning_rate': 2.08588448357125e-06, 'epoch': 0.73}
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-12-19 08:01:32,752 >>   Num examples = 109
[INFO|trainer.py:4648] 2025-12-19 08:01:32,752 >>   Batch size = 1
 77%|            | 525/685 [22:40:41<6:48:54, 153.34s/it][INFO|trainer.py:4309] 2025-12-19 10:31:00,480 >> Saving model checkpoint to /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525
[INFO|configuration_utils.py:491] 2025-12-19 10:31:00,486 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/config.json
{'eval_loss': 0.9934203624725342, 'eval_runtime': 5234.3416, 'eval_samples_per_second': 0.021, 'eval_steps_per_second': 0.007, 'epoch': 0.73}
{'loss': 0.2938, 'grad_norm': 10.234702748222128, 'learning_rate': 2.065201243667335e-06, 'epoch': 0.73}
{'loss': 0.7271, 'grad_norm': 15.865011592911676, 'learning_rate': 2.0445943373566178e-06, 'epoch': 0.73}
{'loss': 1.3098, 'grad_norm': 18.418180090592404, 'learning_rate': 2.02406430062106e-06, 'epoch': 0.73}
{'loss': 0.7449, 'grad_norm': 20.82290192653945, 'learning_rate': 2.0036116674432653e-06, 'epoch': 0.74}
{'loss': 1.3361, 'grad_norm': 21.55840504795173, 'learning_rate': 1.9832369697925786e-06, 'epoch': 0.74}
{'loss': 1.1467, 'grad_norm': 18.630951206219777, 'learning_rate': 1.962940737611264e-06, 'epoch': 0.74}
{'loss': 0.9535, 'grad_norm': 17.94184458610717, 'learning_rate': 1.9427234988006998e-06, 'epoch': 0.74}
{'loss': 1.0915, 'grad_norm': 19.26373255813133, 'learning_rate': 1.922585779207674e-06, 'epoch': 0.74}
{'loss': 0.3742, 'grad_norm': 14.850049105151541, 'learning_rate': 1.9025281026106846e-06, 'epoch': 0.74}
{'loss': 0.9473, 'grad_norm': 19.168097520526395, 'learning_rate': 1.8825509907063328e-06, 'epoch': 0.74}
{'loss': 1.5898, 'grad_norm': 21.79377369830354, 'learning_rate': 1.8626549630957397e-06, 'epoch': 0.75}
{'loss': 2.0909, 'grad_norm': 27.962421642347795, 'learning_rate': 1.8428405372710446e-06, 'epoch': 0.75}
{'loss': 1.0288, 'grad_norm': 16.982560912865768, 'learning_rate': 1.8231082286019342e-06, 'epoch': 0.75}
{'loss': 1.4382, 'grad_norm': 21.480951287530615, 'learning_rate': 1.8034585503222441e-06, 'epoch': 0.75}
{'loss': 0.9902, 'grad_norm': 12.067387390069667, 'learning_rate': 1.7838920135166066e-06, 'epoch': 0.75}
{'loss': 1.4119, 'grad_norm': 20.214245238049568, 'learning_rate': 1.7644091271071645e-06, 'epoch': 0.75}
{'loss': 1.0478, 'grad_norm': 18.550100412428176, 'learning_rate': 1.745010397840321e-06, 'epoch': 0.75}
{'loss': 0.2312, 'grad_norm': 9.718693111923058, 'learning_rate': 1.7256963302735752e-06, 'epoch': 0.76}
{'loss': 1.6298, 'grad_norm': 21.805177416086202, 'learning_rate': 1.706467426762382e-06, 'epoch': 0.76}
{'loss': 0.3033, 'grad_norm': 9.541134809425191, 'learning_rate': 1.687324187447102e-06, 'epoch': 0.76}
{'loss': 0.6436, 'grad_norm': 14.683801651137195, 'learning_rate': 1.6682671102399806e-06, 'epoch': 0.76}
{'loss': 0.7414, 'grad_norm': 13.174651577648042, 'learning_rate': 1.6492966908122033e-06, 'epoch': 0.76}
{'loss': 1.9123, 'grad_norm': 19.76430461769764, 'learning_rate': 1.630413422581001e-06, 'epoch': 0.76}
{'loss': 0.9536, 'grad_norm': 16.346577535567786, 'learning_rate': 1.611617796696821e-06, 'epoch': 0.76}
{'loss': 1.4536, 'grad_norm': 17.632675832167422, 'learning_rate': 1.5929103020305441e-06, 'epoch': 0.77}
[INFO|configuration_utils.py:757] 2025-12-19 10:31:00,487 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/generation_config.json
[INFO|modeling_utils.py:4181] 2025-12-19 10:31:03,497 >> Model weights saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/model.safetensors
[INFO|tokenization_utils_base.py:2421] 2025-12-19 10:31:03,498 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 10:31:03,499 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 10:31:03,499 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/special_tokens_map.json
/home/seohyun/.conda/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
[2025-12-19 10:31:03,635] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step525 is about to be saved!
[2025-12-19 10:31:03,711] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-19 10:31:03,711] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-19 10:31:03,947] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-19 10:31:04,045] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-19 10:31:11,162] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-19 10:31:11,163] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/global_step525/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-19 10:31:12,922] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step525 is ready now!
[INFO|image_processing_base.py:253] 2025-12-19 10:31:12,934 >> Image processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-12-19 10:31:12,935 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 10:31:12,951 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 10:31:12,967 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-12-19 10:31:13,189 >> Video processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-12-19 10:31:13,200 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-525/chat_template.jinja
                                                                                                    
{'loss': 1.9771, 'grad_norm': 21.727389219761687, 'learning_rate': 1.5742914251607794e-06, 'epoch': 0.77}
{'loss': 0.844, 'grad_norm': 16.756844694655403, 'learning_rate': 1.5557616503611977e-06, 'epoch': 0.77}
{'loss': 1.0235, 'grad_norm': 19.988986275597437, 'learning_rate': 1.5373214595879416e-06, 'epoch': 0.77}
{'loss': 1.1426, 'grad_norm': 18.898399911913156, 'learning_rate': 1.5189713324670935e-06, 'epoch': 0.77}
{'loss': 1.4959, 'grad_norm': 20.587863802906337, 'learning_rate': 1.500711746282192e-06, 'epoch': 0.77}
{'loss': 1.1503, 'grad_norm': 18.119431166877547, 'learning_rate': 1.4825431759618208e-06, 'epoch': 0.78}
{'loss': 2.0091, 'grad_norm': 28.32892319237832, 'learning_rate': 1.4644660940672628e-06, 'epoch': 0.78}
{'loss': 0.7934, 'grad_norm': 12.540590374893448, 'learning_rate': 1.4464809707801985e-06, 'epoch': 0.78}
{'loss': 0.7208, 'grad_norm': 14.573381887838046, 'learning_rate': 1.4285882738904822e-06, 'epoch': 0.78}
{'loss': 0.8603, 'grad_norm': 16.765881567811626, 'learning_rate': 1.4107884687839762e-06, 'epoch': 0.78}
{'loss': 0.2345, 'grad_norm': 7.819495151877579, 'learning_rate': 1.3930820184304423e-06, 'epoch': 0.78}
{'loss': 0.8854, 'grad_norm': 16.620881730346667, 'learning_rate': 1.3754693833715e-06, 'epoch': 0.78}
{'loss': 0.8019, 'grad_norm': 15.35788626165932, 'learning_rate': 1.357951021708655e-06, 'epoch': 0.79}
{'loss': 1.2721, 'grad_norm': 20.002867640484812, 'learning_rate': 1.340527389091374e-06, 'epoch': 0.79}
{'loss': 1.6317, 'grad_norm': 22.91632646986835, 'learning_rate': 1.323198938705238e-06, 'epoch': 0.79}
{'loss': 0.7554, 'grad_norm': 15.56588710849119, 'learning_rate': 1.30596612126016e-06, 'epoch': 0.79}
{'loss': 1.1501, 'grad_norm': 27.253061365231066, 'learning_rate': 1.2888293849786503e-06, 'epoch': 0.79}
{'loss': 0.2246, 'grad_norm': 10.034235225404899, 'learning_rate': 1.2717891755841722e-06, 'epoch': 0.79}
{'loss': 1.1659, 'grad_norm': 17.088570112741543, 'learning_rate': 1.2548459362895377e-06, 'epoch': 0.79}
{'loss': 1.1264, 'grad_norm': 18.562636318158884, 'learning_rate': 1.2380001077853833e-06, 'epoch': 0.8}
{'loss': 0.3545, 'grad_norm': 11.181701419801916, 'learning_rate': 1.2212521282287093e-06, 'epoch': 0.8}
{'loss': 1.136, 'grad_norm': 16.850421830428477, 'learning_rate': 1.2046024332314843e-06, 'epoch': 0.8}
{'loss': 1.7555, 'grad_norm': 16.414493243393576, 'learning_rate': 1.188051455849309e-06, 'epoch': 0.8}
{'loss': 0.8642, 'grad_norm': 20.451581066081193, 'learning_rate': 1.1715996265701619e-06, 'epoch': 0.8}
{'loss': 0.3041, 'grad_norm': 11.369348172429282, 'learning_rate': 1.1552473733031893e-06, 'epoch': 0.8}
{'loss': 1.0854, 'grad_norm': 18.9741064114353, 'learning_rate': 1.1389951213675926e-06, 'epoch': 0.8}
{'loss': 1.0335, 'grad_norm': 15.078633293364511, 'learning_rate': 1.1228432934815487e-06, 'epoch': 0.81}
{'loss': 0.7702, 'grad_norm': 15.509156347175663, 'learning_rate': 1.1067923097512256e-06, 'epoch': 0.81}
{'loss': 1.4259, 'grad_norm': 20.62412141306422, 'learning_rate': 1.0908425876598512e-06, 'epoch': 0.81}
{'loss': 0.6603, 'grad_norm': 11.312709898014191, 'learning_rate': 1.0749945420568613e-06, 'epoch': 0.81}
{'loss': 1.3488, 'grad_norm': 24.842018634006635, 'learning_rate': 1.0592485851470973e-06, 'epoch': 0.81}
{'loss': 1.4291, 'grad_norm': 23.29995673931645, 'learning_rate': 1.0436051264800983e-06, 'epoch': 0.81}
{'loss': 1.452, 'grad_norm': 32.48434578093538, 'learning_rate': 1.0280645729394368e-06, 'epoch': 0.81}
{'loss': 1.2059, 'grad_norm': 22.394919099760354, 'learning_rate': 1.0126273287321476e-06, 'epoch': 0.82}
{'loss': 1.1594, 'grad_norm': 12.429553806564874, 'learning_rate': 9.972937953781985e-07, 'epoch': 0.82}
{'loss': 0.559, 'grad_norm': 17.06394565245332, 'learning_rate': 9.820643717000678e-07, 'epoch': 0.82}
{'loss': 1.3974, 'grad_norm': 18.981012928771253, 'learning_rate': 9.6693945381235e-07, 'epoch': 0.82}
{'loss': 1.0675, 'grad_norm': 25.71832990592825, 'learning_rate': 9.519194351114702e-07, 'epoch': 0.82}
{'loss': 0.9349, 'grad_norm': 18.535971514526835, 'learning_rate': 9.370047062654386e-07, 'epoch': 0.82}
{'loss': 1.7084, 'grad_norm': 17.876686773298406, 'learning_rate': 9.221956552036992e-07, 'epoch': 0.82}
{'loss': 0.8836, 'grad_norm': 17.632484107649855, 'learning_rate': 9.074926671070322e-07, 'epoch': 0.83}
{'loss': 0.7465, 'grad_norm': 16.30707495834992, 'learning_rate': 8.928961243975437e-07, 'epoch': 0.83}
{'loss': 1.1381, 'grad_norm': 26.540858713486976, 'learning_rate': 8.784064067287057e-07, 'epoch': 0.83}
{'loss': 0.8393, 'grad_norm': 15.496620680830357, 'learning_rate': 8.640238909754994e-07, 'epoch': 0.83}
{'loss': 0.7831, 'grad_norm': 13.316787080903195, 'learning_rate': 8.497489512245971e-07, 'epoch': 0.83}
{'loss': 0.9364, 'grad_norm': 20.941176386296643, 'learning_rate': 8.355819587646425e-07, 'epoch': 0.83}
{'loss': 1.6364, 'grad_norm': 18.669196156851914, 'learning_rate': 8.215232820765851e-07, 'epoch': 0.84}
{'loss': 0.5559, 'grad_norm': 13.608879540172627, 'learning_rate': 8.075732868241054e-07, 'epoch': 0.84}
{'loss': 1.5478, 'grad_norm': 18.882131523638098, 'learning_rate': 7.937323358440935e-07, 'epoch': 0.84}
{'loss': 1.0078, 'grad_norm': 20.448668829148797, 'learning_rate': 7.800007891372247e-07, 'epoch': 0.84}
{'loss': 1.0261, 'grad_norm': 20.73474241713469, 'learning_rate': 7.663790038585794e-07, 'epoch': 0.84}
{'loss': 0.716, 'grad_norm': 18.408688746738527, 'learning_rate': 7.528673343083715e-07, 'epoch': 0.84}
{'loss': 0.8643, 'grad_norm': 16.81845525465127, 'learning_rate': 7.394661319227175e-07, 'epoch': 0.84}
{'loss': 1.167, 'grad_norm': 18.98151800053827, 'learning_rate': 7.261757452645085e-07, 'epoch': 0.85}
{'loss': 0.3481, 'grad_norm': 11.119259933271191, 'learning_rate': 7.129965200143335e-07, 'epoch': 0.85}
{'loss': 1.1415, 'grad_norm': 20.17906414471489, 'learning_rate': 6.999287989614972e-07, 'epoch': 0.85}
{'loss': 0.5698, 'grad_norm': 17.531490483171584, 'learning_rate': 6.86972921995096e-07, 'epoch': 0.85}
{'loss': 0.3339, 'grad_norm': 14.646453632557227, 'learning_rate': 6.741292260951859e-07, 'epoch': 0.85}
{'loss': 1.0081, 'grad_norm': 12.373316937840201, 'learning_rate': 6.613980453240065e-07, 'epoch': 0.85}
{'loss': 2.1064, 'grad_norm': 26.73709558288285, 'learning_rate': 6.487797108173072e-07, 'epoch': 0.85}
{'loss': 0.5745, 'grad_norm': 15.596298152342527, 'learning_rate': 6.36274550775719e-07, 'epoch': 0.86}
{'loss': 0.6529, 'grad_norm': 14.266856676010757, 'learning_rate': 6.238828904562316e-07, 'epoch': 0.86}
{'loss': 0.855, 'grad_norm': 14.1637991314199, 'learning_rate': 6.116050521637218e-07, 'epoch': 0.86}
{'loss': 0.6273, 'grad_norm': 16.32771179084221, 'learning_rate': 5.994413552425787e-07, 'epoch': 0.86}
{'loss': 0.3092, 'grad_norm': 13.687746292267015, 'learning_rate': 5.873921160683943e-07, 'epoch': 0.86}
{'loss': 0.4865, 'grad_norm': 13.603119022277347, 'learning_rate': 5.754576480397334e-07, 'epoch': 0.86}
{'loss': 1.0674, 'grad_norm': 23.701306729118407, 'learning_rate': 5.636382615699842e-07, 'epoch': 0.86}
{'loss': 1.5526, 'grad_norm': 20.69686616507409, 'learning_rate': 5.519342640792869e-07, 'epoch': 0.87}
{'loss': 1.2554, 'grad_norm': 17.27057294054251, 'learning_rate': 5.403459599865307e-07, 'epoch': 0.87}
{'loss': 0.7724, 'grad_norm': 19.21104353568391, 'learning_rate': 5.288736507014436e-07, 'epoch': 0.87}
{'loss': 0.7875, 'grad_norm': 15.923050330507339, 'learning_rate': 5.175176346167465e-07, 'epoch': 0.87}
{'loss': 0.4966, 'grad_norm': 13.429740704942832, 'learning_rate': 5.062782071003974e-07, 'epoch': 0.87}
{'loss': 1.307, 'grad_norm': 19.70154294428223, 'learning_rate': 4.951556604879049e-07, 'epoch': 0.87}
{'loss': 1.0959, 'grad_norm': 10.712360648998512, 'learning_rate': 4.841502840747253e-07, 'epoch': 0.87}
{'loss': 1.0978, 'grad_norm': 21.105366249279573, 'learning_rate': 4.732623641087403e-07, 'epoch': 0.88}
{'loss': 1.3684, 'grad_norm': 20.905524679125, 'learning_rate': 4.624921837828106e-07, 'epoch': 0.88}
{'loss': 1.4902, 'grad_norm': 16.61401350961777, 'learning_rate': 4.5184002322740784e-07, 'epoch': 0.88}
{'loss': 0.3009, 'grad_norm': 12.213987804750897, 'learning_rate': 4.4130615950333357e-07, 'epoch': 0.88}
{'loss': 1.0619, 'grad_norm': 18.18418642293394, 'learning_rate': 4.3089086659450774e-07, 'epoch': 0.88}
{'loss': 1.088, 'grad_norm': 13.990164106262979, 'learning_rate': 4.205944154008423e-07, 'epoch': 0.88}
{'loss': 0.389, 'grad_norm': 18.078256095785356, 'learning_rate': 4.1041707373120354e-07, 'epoch': 0.88}
{'loss': 1.6498, 'grad_norm': 21.212159356370343, 'learning_rate': 4.0035910629643406e-07, 'epoch': 0.89}
{'loss': 1.6255, 'grad_norm': 17.893038186873046, 'learning_rate': 3.9042077470247574e-07, 'epoch': 0.89}
{'loss': 2.1666, 'grad_norm': 27.266797401837085, 'learning_rate': 3.8060233744356634e-07, 'epoch': 0.89}
{'loss': 0.9143, 'grad_norm': 18.69022407910228, 'learning_rate': 3.709040498955102e-07, 'epoch': 0.89}
{'loss': 0.2981, 'grad_norm': 10.918846204797683, 'learning_rate': 3.613261643090388e-07, 'epoch': 0.89}
{'loss': 1.4162, 'grad_norm': 22.304057910452194, 'learning_rate': 3.518689298032524e-07, 'epoch': 0.89}
{'loss': 0.32, 'grad_norm': 11.139874448297478, 'learning_rate': 3.4253259235913717e-07, 'epoch': 0.89}
{'loss': 1.227, 'grad_norm': 21.73176035590381, 'learning_rate': 3.333173948131663e-07, 'epoch': 0.9}
{'loss': 1.1922, 'grad_norm': 19.58952402227013, 'learning_rate': 3.2422357685098936e-07, 'epoch': 0.9}
{'loss': 1.3147, 'grad_norm': 23.645536829523394, 'learning_rate': 3.1525137500119207e-07, 'epoch': 0.9}
{'loss': 1.2078, 'grad_norm': 16.452282546325637, 'learning_rate': 3.0640102262914584e-07, 'epoch': 0.9}
{'loss': 0.8927, 'grad_norm': 18.595278687834078, 'learning_rate': 2.9767274993094285e-07, 'epoch': 0.9}
{'loss': 0.2246, 'grad_norm': 7.742308389820544, 'learning_rate': 2.890667839273997e-07, 'epoch': 0.9}
{'loss': 0.296, 'grad_norm': 10.549376414973848, 'learning_rate': 2.8058334845816214e-07, 'epoch': 0.91}
{'loss': 0.8556, 'grad_norm': 15.766411907327342, 'learning_rate': 2.722226641758757e-07, 'epoch': 0.91}
{'loss': 0.7622, 'grad_norm': 12.663561090856499, 'learning_rate': 2.6398494854045055e-07, 'epoch': 0.91}
{'loss': 0.2974, 'grad_norm': 10.101011098497787, 'learning_rate': 2.5587041581340235e-07, 'epoch': 0.91}
{'loss': 0.8834, 'grad_norm': 15.514015720535253, 'learning_rate': 2.478792770522842e-07, 'epoch': 0.91}
{'loss': 1.8482, 'grad_norm': 23.225366932581483, 'learning_rate': 2.400117401051921e-07, 'epoch': 0.91}
{'loss': 0.7806, 'grad_norm': 12.626352188365471, 'learning_rate': 2.32268009605362e-07, 'epoch': 0.91}
{'loss': 1.154, 'grad_norm': 16.159245672446442, 'learning_rate': 2.2464828696584506e-07, 'epoch': 0.92}
{'loss': 0.299, 'grad_norm': 10.389840497067388, 'learning_rate': 2.171527703742715e-07, 'epoch': 0.92}
{'loss': 0.2945, 'grad_norm': 13.788326156156144, 'learning_rate': 2.0978165478769298e-07, 'epoch': 0.92}
{'loss': 0.9094, 'grad_norm': 18.553489402069005, 'learning_rate': 2.0253513192751374e-07, 'epoch': 0.92}
{'loss': 2.4867, 'grad_norm': 20.0950247759562, 'learning_rate': 1.9541339027450256e-07, 'epoch': 0.92}
{'loss': 1.7353, 'grad_norm': 23.295257544887487, 'learning_rate': 1.884166150638933e-07, 'epoch': 0.92}
{'loss': 0.9969, 'grad_norm': 21.78043741516005, 'learning_rate': 1.8154498828056255e-07, 'epoch': 0.92}
{'loss': 0.747, 'grad_norm': 18.80616539893223, 'learning_rate': 1.7479868865430072e-07, 'epoch': 0.93}
{'loss': 0.6374, 'grad_norm': 14.968205588614484, 'learning_rate': 1.681778916551591e-07, 'epoch': 0.93}
{'loss': 1.6565, 'grad_norm': 21.819094064860447, 'learning_rate': 1.6168276948889007e-07, 'epoch': 0.93}
{'loss': 0.3387, 'grad_norm': 15.80581884258245, 'learning_rate': 1.5531349109246364e-07, 'epoch': 0.93}
{'loss': 0.8903, 'grad_norm': 14.81197115028204, 'learning_rate': 1.4907022212967803e-07, 'epoch': 0.93}
{'loss': 0.6212, 'grad_norm': 13.399657547797082, 'learning_rate': 1.4295312498684656e-07, 'epoch': 0.93}
{'loss': 0.8706, 'grad_norm': 15.284270041519315, 'learning_rate': 1.3696235876857812e-07, 'epoch': 0.93}
{'loss': 1.4801, 'grad_norm': 22.463407718886533, 'learning_rate': 1.310980792936345e-07, 'epoch': 0.94}
{'loss': 0.426, 'grad_norm': 13.013643971160318, 'learning_rate': 1.253604390908819e-07, 'epoch': 0.94}
{'loss': 0.8404, 'grad_norm': 19.424684872339625, 'learning_rate': 1.1974958739531973e-07, 'epoch': 0.94}
{'loss': 0.9229, 'grad_norm': 21.279169512239385, 'learning_rate': 1.1426567014420297e-07, 'epoch': 0.94}
{'loss': 1.5501, 'grad_norm': 22.887267696725097, 'learning_rate': 1.0890882997324104e-07, 'epoch': 0.94}
{'loss': 1.4334, 'grad_norm': 21.320720774802723, 'learning_rate': 1.0367920621289496e-07, 'epoch': 0.94}
{'loss': 0.2878, 'grad_norm': 11.069757161693847, 'learning_rate': 9.857693488474596e-08, 'epoch': 0.94}
{'loss': 0.3434, 'grad_norm': 14.59653090463073, 'learning_rate': 9.360214869796492e-08, 'epoch': 0.95}
{'loss': 1.7187, 'grad_norm': 22.754013797750144, 'learning_rate': 8.875497704585401e-08, 'epoch': 0.95}
{'loss': 1.777, 'grad_norm': 20.987865844616277, 'learning_rate': 8.403554600248498e-08, 'epoch': 0.95}
{'loss': 0.6713, 'grad_norm': 11.109929478001272, 'learning_rate': 7.944397831941952e-08, 'epoch': 0.95}
{'loss': 0.9775, 'grad_norm': 14.458901872952463, 'learning_rate': 7.498039342251573e-08, 'epoch': 0.95}
{'loss': 0.9475, 'grad_norm': 18.41589842349332, 'learning_rate': 7.064490740882057e-08, 'epoch': 0.95}
{'loss': 0.6369, 'grad_norm': 12.834265717967108, 'learning_rate': 6.643763304355566e-08, 'epoch': 0.95}
{'loss': 1.5413, 'grad_norm': 20.78029074122447, 'learning_rate': 6.23586797571768e-08, 'epoch': 0.96}
{'loss': 0.6484, 'grad_norm': 15.332114013928651, 'learning_rate': 5.8408153642533493e-08, 'epoch': 0.96}
{'loss': 1.2864, 'grad_norm': 16.17719607924965, 'learning_rate': 5.458615745210616e-08, 'epoch': 0.96}
{'loss': 1.3162, 'grad_norm': 17.515505172757287, 'learning_rate': 5.089279059533658e-08, 'epoch': 0.96}
{'loss': 1.0011, 'grad_norm': 16.726808145998508, 'learning_rate': 4.732814913603723e-08, 'epoch': 0.96}
{'loss': 0.6463, 'grad_norm': 13.317545604071967, 'learning_rate': 4.389232578989988e-08, 'epoch': 0.96}
{'loss': 0.2962, 'grad_norm': 10.52332174424107, 'learning_rate': 4.058540992207649e-08, 'epoch': 0.96}
{'loss': 2.0296, 'grad_norm': 22.614234755169047, 'learning_rate': 3.7407487544861565e-08, 'epoch': 0.97}
{'loss': 0.9928, 'grad_norm': 20.116750849129833, 'learning_rate': 3.435864131544897e-08, 'epoch': 0.97}
{'loss': 2.122, 'grad_norm': 24.507384439652242, 'learning_rate': 3.143895053378698e-08, 'epoch': 0.97}
{'loss': 0.2758, 'grad_norm': 9.748472210434885, 'learning_rate': 2.8648491140513267e-08, 'epoch': 0.97}
{'loss': 1.2305, 'grad_norm': 25.394198114083167, 'learning_rate': 2.59873357149798e-08, 'epoch': 0.97}
{'loss': 1.1439, 'grad_norm': 15.207266065191462, 'learning_rate': 2.345555347336548e-08, 'epoch': 0.97}
{'loss': 0.8094, 'grad_norm': 18.13001668721673, 'learning_rate': 2.1053210266875346e-08, 'epoch': 0.98}
{'loss': 1.4211, 'grad_norm': 20.946878077296777, 'learning_rate': 1.8780368580029185e-08, 'epoch': 0.98}
{'loss': 0.9236, 'grad_norm': 18.998513802922933, 'learning_rate': 1.6637087529033925e-08, 'epoch': 0.98}
{'loss': 1.4281, 'grad_norm': 23.591624661212105, 'learning_rate': 1.4623422860248205e-08, 'epoch': 0.98}
{'loss': 1.7293, 'grad_norm': 21.75867494671568, 'learning_rate': 1.2739426948732426e-08, 'epoch': 0.98}
{'loss': 1.4001, 'grad_norm': 18.14687558838231, 'learning_rate': 1.0985148796883726e-08, 'epoch': 0.98}
{'loss': 0.6846, 'grad_norm': 12.66518633754204, 'learning_rate': 9.36063403316534e-09, 'epoch': 0.98}
{'loss': 0.8815, 'grad_norm': 18.063664494022152, 'learning_rate': 7.865924910916977e-09, 'epoch': 0.99}
{'loss': 0.2217, 'grad_norm': 7.872580144957446, 'learning_rate': 6.501060307256835e-09, 'epoch': 0.99}
{'loss': 1.2183, 'grad_norm': 23.20658707928587, 'learning_rate': 5.266075722070163e-09, 'epoch': 0.99}
{'loss': 2.1969, 'grad_norm': 25.956941165597858, 'learning_rate': 4.161003277085574e-09, 'epoch': 0.99}
{'loss': 2.1407, 'grad_norm': 18.683614687460295, 'learning_rate': 3.1858717150412554e-09, 'epoch': 0.99}
{'loss': 0.7709, 'grad_norm': 15.885102099009346, 'learning_rate': 2.3407063989361324e-09, 'epoch': 0.99}
{'loss': 0.2715, 'grad_norm': 11.452587086000564, 'learning_rate': 1.6255293113687232e-09, 'epoch': 0.99}
{'loss': 0.2989, 'grad_norm': 11.728400597428333, 'learning_rate': 1.040359053967599e-09, 'epoch': 1.0}
{'loss': 1.2731, 'grad_norm': 18.27557632924718, 'learning_rate': 5.852108469073248e-10, 'epoch': 1.0}
{'loss': 0.3027, 'grad_norm': 11.66275144605761, 'learning_rate': 2.6009652851211044e-10, 'epoch': 1.0}
{'loss': 1.2734, 'grad_norm': 18.447404163214593, 'learning_rate': 6.502455494716841e-11, 'epoch': 1.0}
[INFO|configuration_utils.py:491] 2025-12-19 17:14:33,852 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/config.json
[INFO|configuration_utils.py:757] 2025-12-19 17:14:33,853 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/generation_config.json
[INFO|modeling_utils.py:4181] 2025-12-19 17:14:36,821 >> Model weights saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/model.safetensors
[INFO|tokenization_utils_base.py:2421] 2025-12-19 17:14:36,822 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 17:14:36,822 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 17:14:36,823 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/special_tokens_map.json
/home/seohyun/.conda/envs/llama_factory/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
[2025-12-19 17:14:36,960] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step685 is about to be saved!
[2025-12-19 17:14:37,037] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-19 17:14:37,037] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-19 17:14:37,302] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-19 17:14:37,341] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-19 17:14:43,986] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-19 17:14:43,987] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/global_step685/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-19 17:14:46,581] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step685 is ready now!
[INFO|image_processing_base.py:253] 2025-12-19 17:14:46,597 >> Image processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-12-19 17:14:46,605 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 17:14:46,616 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 17:14:46,624 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-12-19 17:14:46,888 >> Video processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-12-19 17:14:46,893 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-685/chat_template.jinja
[INFO|trainer.py:2810] 2025-12-19 17:14:47,195 >>

Training completed. Do not forget to share your model on huggingface.co/models =)


100%|| 685/685 [29:24:36<00:00, 154.56s/it]
{'train_runtime': 105878.7355, 'train_samples_per_second': 0.019, 'train_steps_per_second': 0.006, 'train_loss': 1.2255634360939918, 'epoch': 1.0}
[INFO|image_processing_base.py:253] 2025-12-19 17:14:47,203 >> Image processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-12-19 17:14:47,203 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 17:14:47,204 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 17:14:47,204 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-12-19 17:14:47,313 >> Video processor saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-12-19 17:14:47,314 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/chat_template.jinja
[INFO|trainer.py:4309] 2025-12-19 17:14:51,820 >> Saving model checkpoint to /hub_data4/seohyun/saves/ecva_instruct/full/sft
[INFO|configuration_utils.py:491] 2025-12-19 17:14:51,825 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/config.json
[INFO|configuration_utils.py:757] 2025-12-19 17:14:51,825 >> Configuration saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/generation_config.json
[INFO|modeling_utils.py:4181] 2025-12-19 17:14:54,104 >> Model weights saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/model.safetensors
[INFO|tokenization_utils_base.py:2421] 2025-12-19 17:14:54,117 >> chat template saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-12-19 17:14:54,130 >> tokenizer config file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-12-19 17:14:54,143 >> Special tokens file saved in /hub_data4/seohyun/saves/ecva_instruct/full/sft/special_tokens_map.json
***** train metrics *****
  epoch                    =               1.0
  total_flos               =           28122GF
  train_loss               =            1.2256
  train_runtime            = 1 day, 5:24:38.73
  train_samples_per_second =             0.019
  train_steps_per_second   =             0.006
Figure saved at: /hub_data4/seohyun/saves/ecva_instruct/full/sft/training_loss.png
Figure saved at: /hub_data4/seohyun/saves/ecva_instruct/full/sft/training_eval_loss.png
[WARNING|2025-12-19 17:14:54] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
[INFO|trainer.py:4643] 2025-12-19 17:14:54,822 >>
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-12-19 17:14:54,822 >>   Num examples = 109
[INFO|trainer.py:4648] 2025-12-19 17:14:54,822 >>   Batch size = 1
 43%|                                                                 | 16/37 [35:43<50:16, 143.64s/it]
